{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf625d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROIs for drg4_all_e7_n48.csv saved in /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DBScan_Rois/DRG4_roi/drg4_all_e7_n48\n",
      "All CSV files have been processed. ROIs are saved in /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DBScan_Rois/DRG4_roi.\n"
     ]
    }
   ],
   "source": [
    "#CSV to Roi folder Part 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from roifile import ImagejRoi, roiwrite\n",
    "import os\n",
    "\n",
    "# Input folder containing CSV files\n",
    "input_folder = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DBScan_Rois/DRG4'# Replace with the path to your folder of CSVs\n",
    "# Output folder to store all ROI subfolders\n",
    "output_folder = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DBScan_Rois/DRG4_roi'  # Replace with the path to the folder where ROI subfolders will be created\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create the main output folder if it doesn't exist\n",
    "\n",
    "# Loop through each CSV file in the input folder\n",
    "for csv_file in os.listdir(input_folder):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        # Full path to the current CSV file\n",
    "        input_csv_path = os.path.join(input_folder, csv_file)\n",
    "        \n",
    "        # Read the CSV into a DataFrame\n",
    "        data = pd.read_csv(input_csv_path)\n",
    "        \n",
    "        # Create a subfolder for this CSV's ROI files\n",
    "        csv_name = os.path.splitext(csv_file)[0]  # Get the CSV name without the .csv extension\n",
    "        roi_folder = os.path.join(output_folder, csv_name)  # Subfolder for the ROIs of this CSV\n",
    "        os.makedirs(roi_folder, exist_ok=True)  # Create subfolder if it doesn't exist\n",
    "\n",
    "        # Initialize a counter for sequential numbering\n",
    "        roi_counter = 1\n",
    "\n",
    "        # Group by 'Name' and create ROIscell_id for each group\n",
    "        for _, group in data.groupby('Name'):\n",
    "            # Extract coordinates\n",
    "            coordinates = group[['X', 'Y']].to_numpy()\n",
    "            \n",
    "            # Create an ROI for the cell\n",
    "            roi = ImagejRoi.frompoints(coordinates)\n",
    "            \n",
    "            # Save the ROI with sequential numbering\n",
    "            roi_file = os.path.join(roi_folder, f\"roi_{roi_counter}.roi\")\n",
    "            roiwrite(roi_file, roi)\n",
    "            \n",
    "            # Increment the counter\n",
    "            roi_counter += 1\n",
    "\n",
    "        print(f\"ROIs for {csv_file} saved in {roi_folder}\")\n",
    "\n",
    "print(f\"All CSV files have been processed. ROIs are saved in {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8781f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ROIs zipped into /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DBScan_Rois/drg4_all_e7_n48.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Standardized Pipelines for Pub'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CSV to ROI part 2 ZIP\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Folder containing the ROI files\n",
    "roi_folder = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DBScan_Rois/drg4_all_e7_n48'  # Replace with your folder path\n",
    "zip_file = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DBScan_Rois/drg4_all_e7_n48.zip'  # Desired ZIP file name\n",
    "\n",
    "# Create a ZIP archive of all ROIs\n",
    "with zipfile.ZipFile(zip_file, 'w') as zipf:\n",
    "    for file in os.listdir(roi_folder):\n",
    "        if file.endswith('.roi'):  # Only include .roi files\n",
    "            file_path = os.path.join(roi_folder, file)\n",
    "            zipf.write(file_path, arcname=file)  # Add file to ZIP archive\n",
    "\n",
    "print(f\"All ROIs zipped into {zip_file}\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV to TXT \n",
    "#Enter Path to CSV in Link\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Input folder containing CSV files\n",
    "input_folder = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Figures/Evaluation Image/ManualDRG4'  # Replace with the path to your folder of CSVs\n",
    "# Output folder to store all TXT files\n",
    "output_folder = '//home/yhs/Documents'  # Replace with the path to your folder for TXT files\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "\n",
    "# Loop through each CSV file in the input folder\n",
    "for csv_file in os.listdir(input_folder):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        # Full path to the current CSV file\n",
    "        input_csv_path = os.path.join(input_folder, csv_file)\n",
    "        \n",
    "        # Read the CSV into a DataFrame\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "        \n",
    "        # Group the data by 'Name' and prepare the coordinates as lists\n",
    "        grouped = df.groupby('Name')\n",
    "\n",
    "        # Initialize a list to store the lines to write to the TXT file\n",
    "        lines = []\n",
    "\n",
    "        # Process each group of cells (grouped by 'Name')\n",
    "        for cell, group in grouped:\n",
    "            # Start with the cell ID (the 'class' in YOLO format)\n",
    "            line = f\"0\"  # Assuming class '0' for all cells, adjust if needed\n",
    "\n",
    "            # Add coordinates to the line\n",
    "            for _, row in group.iterrows():\n",
    "                # The CSV has columns 'X' and 'Y' which are the coordinates\n",
    "                line += f\" {row['X'] / 500} {row['Y'] / 500}\"  # Divide by 500 to normalize coordinates\n",
    "            \n",
    "            # Add this line to the list\n",
    "            lines.append(line)\n",
    "\n",
    "        # Create a corresponding TXT filename\n",
    "        txt_filename = os.path.splitext(csv_file)[0] + '.txt'  # Change .csv to .txt\n",
    "        output_txt_path = os.path.join(output_folder, txt_filename)\n",
    "        \n",
    "        # Write the lines to the output TXT file\n",
    "        with open(output_txt_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        \n",
    "        print(f\"Converted {csv_file} to {txt_filename} and saved to {output_folder}\")\n",
    "\n",
    "print(f\"All CSV files have been converted and saved as TXT files in {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c96c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV to GEOJSON\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV\n",
    "csv_file = '/home/yhs/Desktop/Segmentation file format/evaluation.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Initialize a dictionary with the 'geometries' key\n",
    "geojson_format = {'geometries': []}\n",
    "\n",
    "# Group by 'name' and create polygons\n",
    "for name, group in data.groupby('Name'):\n",
    "    # Extract coordinates as a list of [x, y] pairs\n",
    "    coordinates = group[['X', 'Y']].to_numpy().tolist()\n",
    "    \n",
    "    # Ensure the polygon is closed (repeat the first coordinate at the end if needed)\n",
    "    if coordinates[0] != coordinates[-1]:\n",
    "        coordinates.append(coordinates[0])\n",
    "    \n",
    "    # Append the polygon entry to the 'geometries' list\n",
    "    geojson_format['geometries'].append({\n",
    "        'coordinates': [coordinates],  # GeoJSON expects a nested list\n",
    "        'type': 'Polygon',\n",
    "        'cell': name  # Use the 'name' as the cell identifier\n",
    "    })\n",
    "\n",
    "# Save to a JSON file\n",
    "output_file = 'baysor_geometries.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(geojson_format, f, indent=4)\n",
    "\n",
    "print(f\"GeoJSON-like file saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV to NumPy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Input folder containing CSV files\n",
    "input_folder = '/path/to/your/input/csv/folder'  # Replace with the path to your folder of CSVs\n",
    "# Output folder to store all NumPy files\n",
    "output_folder = '/path/to/your/output/numpy/folder'  # Replace with the path to your folder for NumPy files\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "\n",
    "# Image size for the binary mask\n",
    "image_size = (512, 512)  # You can adjust this as needed\n",
    "\n",
    "# Loop through each CSV file in the input folder\n",
    "for csv_file in os.listdir(input_folder):\n",
    "    if csv_file.endswith('.csv'):\n",
    "        # Full path to the current CSV file\n",
    "        input_csv_path = os.path.join(input_folder, csv_file)\n",
    "        \n",
    "        # Read the CSV into a DataFrame\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "        \n",
    "        # Create a blank 512x512 binary array\n",
    "        binary_array = np.zeros(image_size, dtype=np.uint8)\n",
    "        \n",
    "        # Group points by 'Cell' and fill the mask\n",
    "        for cell_label, group in df.groupby(\"Cell\"):\n",
    "            # Extract the contour points for this cell\n",
    "            contour = group[[\"X\", \"Y\"]].to_numpy().astype(np.int32)\n",
    "            contour = contour.reshape((-1, 1, 2))  # Reshape for OpenCV format\n",
    "            \n",
    "            # Fill the polygon (square, rectangle, etc.) inside the contour\n",
    "            cv2.fillPoly(binary_array, [contour], 1)  # Fill inside the polygon with 1's\n",
    "\n",
    "        # Create a corresponding NumPy filename\n",
    "        numpy_filename = os.path.splitext(csv_file)[0] + '.npy'  # Change .csv to .npy\n",
    "        output_numpy_path = os.path.join(output_folder, numpy_filename)\n",
    "        \n",
    "        # Save the NumPy array\n",
    "        np.save(output_numpy_path, binary_array)\n",
    "        \n",
    "        print(f\"Converted {csv_file} to {numpy_filename} and saved to {output_folder}\")\n",
    "\n",
    "print(f\"All CSV files have been converted and saved as NumPy files in {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec36fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted DRG_1_SegTrans_2000_3000.txt to DRG_1_SegTrans_2000_3000.csv and saved to /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/FinalProjectPlots/DBScan_HY/Images/new_Crop/out\n",
      "All TXT files have been converted and saved as CSV files in /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/FinalProjectPlots/DBScan_HY/Images/new_Crop/out.\n"
     ]
    }
   ],
   "source": [
    "#TXT to CSV\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Input folder containing TXT files\n",
    "input_folder = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/FinalProjectPlots/DBScan_HY/Images/new_Crop/in'  # Replace with the path to your folder of TXT files\n",
    "# Output folder to store all CSV files\n",
    "output_folder = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/FinalProjectPlots/DBScan_HY/Images/new_Crop/out'  # Replace with the path to your folder for CSV files\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "\n",
    "# Loop through each TXT file in the input folder\n",
    "for txt_file in os.listdir(input_folder):\n",
    "    if txt_file.endswith('.txt'):\n",
    "        # Full path to the current TXT file\n",
    "        input_txt_path = os.path.join(input_folder, txt_file)\n",
    "        \n",
    "        # Read the YOLOv8 TXT file line by line\n",
    "        with open(input_txt_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Initialize an empty list to store rows\n",
    "        rows = []\n",
    "\n",
    "        # Process each line\n",
    "        for cell_index, line in enumerate(lines):\n",
    "            # Split the line into components\n",
    "            components = line.strip().split()\n",
    "            \n",
    "            # Scale X and Y by first and second number specified\n",
    "            coordinates = [round(float(components[i]) * 5797 if i % 2 == 0 else float(components[i]) * 7261) for i in range(1, len(components))]\n",
    "            \n",
    "            # Reshape coordinates into pairs of (x, y)\n",
    "            coordinates_pairs = [(coordinates[i], coordinates[i+1]) for i in range(0, len(coordinates), 2)]\n",
    "            \n",
    "            # Create a row for each cell, include the cell ID and all coordinates\n",
    "            rows.append({'Name': f'ROI_{cell_index + 1}', 'Coordinates': coordinates_pairs})\n",
    "\n",
    "        # Convert rows to a DataFrame\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        # Expand the DataFrame so each coordinate gets its own row\n",
    "        expanded_rows = []\n",
    "        for _, row in df.iterrows():\n",
    "            cell_id = row['Name']\n",
    "            for x, y in row['Coordinates']:\n",
    "                expanded_rows.append({'Name': cell_id, 'X': x, 'Y': y})\n",
    "\n",
    "        expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "        # Create a corresponding CSV filename\n",
    "        csv_filename = os.path.splitext(txt_file)[0] + '.csv'  # Change .txt to .csv\n",
    "        output_csv_path = os.path.join(output_folder, csv_filename)\n",
    "        \n",
    "        # Save the CSV file\n",
    "        expanded_df.to_csv(output_csv_path, index=False)\n",
    "        \n",
    "        print(f\"Converted {txt_file} to {csv_filename} and saved to {output_folder}\")\n",
    "\n",
    "print(f\"All TXT files have been converted and saved as CSV files in {output_folder}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e87416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMPY to CSV \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Input folder containing NumPy (.npy) files\n",
    "input_folder = '/home/yhs/Desktop/combo_DRG4'  # Replace with the path to your folder of NumPy files\n",
    "# Output folder to store all CSV files\n",
    "output_folder = '/home/yhs/Desktop/combo_DRG4/csv'  # Replace with the path to your folder for CSV files\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "\n",
    "# Loop through each NumPy file in the input folder\n",
    "for npy_file in os.listdir(input_folder):\n",
    "    if npy_file.endswith('.npy'):\n",
    "        # Full path to the current NumPy file\n",
    "        input_npy_path = os.path.join(input_folder, npy_file)\n",
    "        \n",
    "        # Step 1: Load the NumPy array from the file\n",
    "        binary_array = np.load(input_npy_path)\n",
    "\n",
    "        # Step 2: Ensure the array is binary (0s and 1s)\n",
    "        binary_array = (binary_array > 0).astype(np.uint8)\n",
    "\n",
    "        # Step 3: Find contours using OpenCV\n",
    "        contours, _ = cv2.findContours(binary_array, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Step 4: Prepare data for CSV\n",
    "        data = []\n",
    "        for cell_id, contour in enumerate(contours, start=1):\n",
    "            cell_label = f\"Cell_{cell_id}\"  # Add prefix like \"Cell_1\", \"Cell_2\", etc.\n",
    "            for point in contour:\n",
    "                x, y = point[0]  # OpenCV returns [x, y] format\n",
    "                data.append({\"Cell\": cell_label, \"X\": x, \"Y\": y})\n",
    "\n",
    "        # Step 5: Create DataFrame and save to CSV\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Create a corresponding CSV filename (same name as the .npy file)\n",
    "        csv_filename = os.path.splitext(npy_file)[0] + '.csv'  # Change .npy to .csv\n",
    "        output_csv_path = os.path.join(output_folder, csv_filename)\n",
    "\n",
    "        # Save the CSV file\n",
    "        df.to_csv(output_csv_path, index=False)\n",
    "        \n",
    "        print(f\"Converted {npy_file} to {csv_filename} and saved to {output_folder}\")\n",
    "\n",
    "print(f\"All NumPy files have been converted and saved as CSV files in {output_folder}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99cd011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEOJSON to CSV \n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Xenium_segementation/Baysor/DRG_1_1gene/DRG_1_4/segmentation_polygons.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "new_data = data.get('geometries')\n",
    "\n",
    "# Now 'data' contains the JSON data loaded from the file\n",
    "df_data = {'Name': [], 'X': [], 'Y': []}\n",
    "counter = 0\n",
    "for i in range(len(new_data)):\n",
    "    counter = counter+1\n",
    "    coords = new_data[i]['coordinates'][0]\n",
    "    for k in range(len(coords)):\n",
    "        df_data['Name'].extend(['roi'+str(counter)])\n",
    "        df_data['X'].extend([round(coords[k][0])])\n",
    "        df_data['Y'].extend([round(coords[k][1])])\n",
    "        \n",
    "df = pd.DataFrame.from_dict(df_data)\n",
    "                             \n",
    "    \n",
    "name_counts = df['Name'].value_counts()\n",
    "\n",
    "# Filter out rows where the Name appears less than 4 times\n",
    "df_filtered = df[df['Name'].isin(name_counts[name_counts >= 4].index)]\n",
    "out_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Xenium_segementation/Baysor/DRG_1_1gene/DRG_1_4/DRG_1_1_gene_trial_4.csv'\n",
    "df_filtered.to_csv(out_path, sep=',', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449452b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 09253-05421.roi: 'x'\n",
      "Error processing 04456-12122.roi: 'x'\n",
      "Error processing 13572-04841.roi: 'x'\n",
      "Error processing 07510-16932.roi: 'x'\n",
      "Error processing 07418-10856.roi: 'x'\n",
      "Error processing 16630-10213.roi: 'x'\n",
      "Error processing 06851-07694.roi: 'x'\n",
      "Error processing 14716-12918.roi: 'x'\n",
      "Error processing 11435-08107.roi: 'x'\n",
      "Error processing 04649-15772.roi: 'x'\n",
      "CSV file saved to /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Xenium_segementation/ManuscriptProject/Manual_Cell_ids_csvs/cellids11.csv\n"
     ]
    }
   ],
   "source": [
    "#ROI TO CSV \n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from read_roi import read_roi_file\n",
    "\n",
    "# Specify the folder path containing the .roi files\n",
    "roi_folder = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/export/RoiSet/XETG00171__0018220_DRG-Region_1_RoiSet'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize empty lists to store the coordinates and cell IDs\n",
    "final_x = []\n",
    "final_y = []\n",
    "final_l = []\n",
    "\n",
    "# Get a list of all .roi files in the specified folder\n",
    "dir_list = [f for f in os.listdir(roi_folder) if f.endswith('.roi')]\n",
    "\n",
    "# Loop through each ROI file in the folder\n",
    "for roi_file in dir_list:\n",
    "    try:\n",
    "        # Construct the full path to the ROI file\n",
    "        roi_path = os.path.join(roi_folder, roi_file)\n",
    "        \n",
    "        # Read the ROI file\n",
    "        roi = read_roi_file(roi_path)\n",
    "        r2 = roi.keys()\n",
    "        name = roi[list(r2)[0]]['name']\n",
    "        x_cord = roi[list(r2)[0]]['x']\n",
    "        y_cord = roi[list(r2)[0]]['y']\n",
    "        \n",
    "        # Append data to the lists\n",
    "        l = [name] * len(x_cord)  # Repeat the name for each point\n",
    "        final_x += x_cord\n",
    "        final_y += y_cord\n",
    "        final_l += l\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {roi_file}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "data = {'cell_id': final_l, 'x': final_x, 'y': final_y}\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Specify the output CSV file path\n",
    "output_csv = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Xenium_segementation/ManuscriptProject/Manual_Cell_ids_csvs/cellids11.csv'  # Replace with the desired output path\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Clean up memory\n",
    "gc.collect()\n",
    "\n",
    "print(f\"CSV file saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84787b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
