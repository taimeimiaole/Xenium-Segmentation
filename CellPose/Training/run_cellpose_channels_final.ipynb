{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a368e9-1dfa-401d-b9ea-d6da4cb30e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n",
      "2025-05-25 13:39:00,067 [INFO] ** TORCH CUDA version installed and working. **\n",
      ">>> GPU activated? YES\n",
      "None\n",
      "[('DRG_1_SegTrans_3000_1500.txt', 'DRG_1_SegTrans_3000_1500.jpg'), ('DRG_2_SegTrans_0_4000.txt', 'DRG_2_SegTrans_0_4000.jpg'), ('DRG_1_SegTrans_1500_1500.txt', 'DRG_1_SegTrans_1500_1500.jpg'), ('DRG_3_SegTrans_1000_1500.txt', 'DRG_3_SegTrans_1000_1500.jpg'), ('DRG_2_SegTrans_0_3000.txt', 'DRG_2_SegTrans_0_3000.jpg'), ('DRG_1_SegTrans_1500_2500.txt', 'DRG_1_SegTrans_1500_2500.jpg')]\n",
      "[('DRG_2_SegTrans_0_4000.csv', 'DRG_2_SegTrans_0_4000.jpg'), ('DRG_1_SegTrans_1500_2500.csv', 'DRG_1_SegTrans_1500_2500.jpg'), ('DRG_1_SegTrans_1500_1500.csv', 'DRG_1_SegTrans_1500_1500.jpg'), ('DRG_3_SegTrans_1000_1500.csv', 'DRG_3_SegTrans_1000_1500.jpg'), ('DRG_1_SegTrans_3000_1500.csv', 'DRG_1_SegTrans_3000_1500.jpg'), ('DRG_2_SegTrans_0_3000.csv', 'DRG_2_SegTrans_0_3000.jpg')]\n",
      "[('DRG_3_SegTrans_3000_1500.txt', 'DRG_3_SegTrans_3000_1500.jpg'), ('DRG_1_SegTrans_2000_2500.txt', 'DRG_1_SegTrans_2000_2500.jpg'), ('DRG_1_SegTrans_1000_1500.txt', 'DRG_1_SegTrans_1000_1500.jpg'), ('DRG_3_SegTrans_2500_2000.txt', 'DRG_3_SegTrans_2500_2000.jpg'), ('DRG_1_SegTrans_500_2000.txt', 'DRG_1_SegTrans_500_2000.jpg'), ('DRG_2_SegTrans_1000_1000.txt', 'DRG_2_SegTrans_1000_1000.jpg'), ('DRG_3_SegTrans_1500_2500.txt', 'DRG_3_SegTrans_1500_2500.jpg'), ('DRG_2_SegTrans_500_500.txt', 'DRG_2_SegTrans_500_500.jpg')]\n",
      "[('DRG_3_SegTrans_3000_1500.csv', 'DRG_3_SegTrans_3000_1500.jpg'), ('DRG_2_SegTrans_1000_1000.csv', 'DRG_2_SegTrans_1000_1000.jpg'), ('DRG_1_SegTrans_1000_1500.csv', 'DRG_1_SegTrans_1000_1500.jpg'), ('DRG_2_SegTrans_500_500.csv', 'DRG_2_SegTrans_500_500.jpg'), ('DRG_3_SegTrans_2500_2000.csv', 'DRG_3_SegTrans_2500_2000.jpg'), ('DRG_1_SegTrans_2000_2500.csv', 'DRG_1_SegTrans_2000_2500.jpg'), ('DRG_3_SegTrans_1500_2500.csv', 'DRG_3_SegTrans_1500_2500.jpg'), ('DRG_1_SegTrans_500_2000.csv', 'DRG_1_SegTrans_500_2000.jpg')]\n",
      "[('DRG_2_SegTrans_0_2500.txt', 'DRG_2_SegTrans_0_2500.jpg'), ('DRG_1_SegTrans_1000_1000.txt', 'DRG_1_SegTrans_1000_1000.jpg'), ('DRG_1_SegTrans_2500_2500.txt', 'DRG_1_SegTrans_2500_2500.jpg'), ('DRG_3_SegTrans_1500_2000.txt', 'DRG_3_SegTrans_1500_2000.jpg'), ('DRG_2_SegTrans_500_4000.txt', 'DRG_2_SegTrans_500_4000.jpg'), ('DRG_2_SegTrans_500_3500.txt', 'DRG_2_SegTrans_500_3500.jpg'), ('DRG_2_SegTrans_1000_3000.txt', 'DRG_2_SegTrans_1000_3000.jpg'), ('DRG_1_SegTrans_1000_2000.txt', 'DRG_1_SegTrans_1000_2000.jpg'), ('DRG_3_SegTrans_500_1000.txt', 'DRG_3_SegTrans_500_1000.jpg'), ('DRG_1_SegTrans_3000_2000.txt', 'DRG_1_SegTrans_3000_2000.jpg'), ('DRG_1_SegTrans_1500_2000.txt', 'DRG_1_SegTrans_1500_2000.jpg'), ('DRG_1_SegTrans_2500_1000.txt', 'DRG_1_SegTrans_2500_1000.jpg'), ('DRG_3_SegTrans_2500_2500.txt', 'DRG_3_SegTrans_2500_2500.jpg'), ('DRG_1_SegTrans_500_2500.txt', 'DRG_1_SegTrans_500_2500.jpg'), ('DRG_2_SegTrans_500_2000.txt', 'DRG_2_SegTrans_500_2000.jpg'), ('DRG_3_SegTrans_500_2500.txt', 'DRG_3_SegTrans_500_2500.jpg'), ('DRG_3_SegTrans_2000_1500.txt', 'DRG_3_SegTrans_2000_1500.jpg'), ('DRG_3_SegTrans_2000_2000.txt', 'DRG_3_SegTrans_2000_2000.jpg'), ('DRG_3_SegTrans_3000_2000.txt', 'DRG_3_SegTrans_3000_2000.jpg'), ('DRG_2_SegTrans_500_1500.txt', 'DRG_2_SegTrans_500_1500.jpg'), ('DRG_1_SegTrans_2500_2000.txt', 'DRG_1_SegTrans_2500_2000.jpg'), ('DRG_1_SegTrans_1000_2500.txt', 'DRG_1_SegTrans_1000_2500.jpg'), ('DRG_2_SegTrans_1500_2500.txt', 'DRG_2_SegTrans_1500_2500.jpg'), ('DRG_3_SegTrans_500_1500.txt', 'DRG_3_SegTrans_500_1500.jpg'), ('DRG_2_SegTrans_500_2500.txt', 'DRG_2_SegTrans_500_2500.jpg'), ('DRG_1_SegTrans_1500_3000.txt', 'DRG_1_SegTrans_1500_3000.jpg'), ('DRG_3_SegTrans_1500_1500.txt', 'DRG_3_SegTrans_1500_1500.jpg'), ('DRG_2_SegTrans_1000_3500.txt', 'DRG_2_SegTrans_1000_3500.jpg'), ('DRG_1_SegTrans_1500_1000.txt', 'DRG_1_SegTrans_1500_1000.jpg'), ('DRG_1_SegTrans_3000_2500.txt', 'DRG_1_SegTrans_3000_2500.jpg'), ('DRG_1_SegTrans_500_3000.txt', 'DRG_1_SegTrans_500_3000.jpg'), ('DRG_2_SegTrans_0_3500.txt', 'DRG_2_SegTrans_0_3500.jpg'), ('DRG_1_SegTrans_2000_1500.txt', 'DRG_1_SegTrans_2000_1500.jpg'), ('DRG_1_SegTrans_2500_3000.txt', 'DRG_1_SegTrans_2500_3000.jpg'), ('DRG_2_SegTrans_500_3000.txt', 'DRG_2_SegTrans_500_3000.jpg'), ('DRG_2_SegTrans_1000_2500.txt', 'DRG_2_SegTrans_1000_2500.jpg'), ('DRG_1_SegTrans_2000_2000.txt', 'DRG_1_SegTrans_2000_2000.jpg'), ('DRG_3_SegTrans_2000_2500.txt', 'DRG_3_SegTrans_2000_2500.jpg'), ('DRG_3_SegTrans_1000_1000.txt', 'DRG_3_SegTrans_1000_1000.jpg'), ('DRG_2_SegTrans_1000_1500.txt', 'DRG_2_SegTrans_1000_1500.jpg'), ('DRG_2_SegTrans_1000_2000.txt', 'DRG_2_SegTrans_1000_2000.jpg'), ('DRG_3_SegTrans_500_2000.txt', 'DRG_3_SegTrans_500_2000.jpg'), ('DRG_1_SegTrans_2000_1000.txt', 'DRG_1_SegTrans_2000_1000.jpg'), ('DRG_1_SegTrans_2500_1500.txt', 'DRG_1_SegTrans_2500_1500.jpg'), ('DRG_1_SegTrans_2000_3000.txt', 'DRG_1_SegTrans_2000_3000.jpg'), ('DRG_1_SegTrans_1000_3000.txt', 'DRG_1_SegTrans_1000_3000.jpg'), ('DRG_1_SegTrans_500_1500.txt', 'DRG_1_SegTrans_500_1500.jpg'), ('DRG_1_SegTrans_2500_500.txt', 'DRG_1_SegTrans_2500_500.jpg'), ('DRG_3_SegTrans_1000_2000.txt', 'DRG_3_SegTrans_1000_2000.jpg')]\n",
      "[('DRG_1_SegTrans_2500_2500.csv', 'DRG_1_SegTrans_2500_2500.jpg'), ('DRG_2_SegTrans_500_4000.csv', 'DRG_2_SegTrans_500_4000.jpg'), ('DRG_2_SegTrans_500_1500.csv', 'DRG_2_SegTrans_500_1500.jpg'), ('DRG_2_SegTrans_500_3000.csv', 'DRG_2_SegTrans_500_3000.jpg'), ('DRG_3_SegTrans_1500_2000.csv', 'DRG_3_SegTrans_1500_2000.jpg'), ('DRG_1_SegTrans_500_1500.csv', 'DRG_1_SegTrans_500_1500.jpg'), ('DRG_1_SegTrans_500_3000.csv', 'DRG_1_SegTrans_500_3000.jpg'), ('DRG_1_SegTrans_500_2500.csv', 'DRG_1_SegTrans_500_2500.jpg'), ('DRG_2_SegTrans_1000_1500.csv', 'DRG_2_SegTrans_1000_1500.jpg'), ('DRG_2_SegTrans_0_3500.csv', 'DRG_2_SegTrans_0_3500.jpg'), ('DRG_1_SegTrans_2000_1500.csv', 'DRG_1_SegTrans_2000_1500.jpg'), ('DRG_3_SegTrans_500_2000.csv', 'DRG_3_SegTrans_500_2000.jpg'), ('DRG_1_SegTrans_1000_2000.csv', 'DRG_1_SegTrans_1000_2000.jpg'), ('DRG_2_SegTrans_0_2500.csv', 'DRG_2_SegTrans_0_2500.jpg'), ('DRG_1_SegTrans_1500_3000.csv', 'DRG_1_SegTrans_1500_3000.jpg'), ('DRG_2_SegTrans_500_3500.csv', 'DRG_2_SegTrans_500_3500.jpg'), ('DRG_1_SegTrans_2500_3000.csv', 'DRG_1_SegTrans_2500_3000.jpg'), ('DRG_1_SegTrans_1000_2500.csv', 'DRG_1_SegTrans_1000_2500.jpg'), ('DRG_2_SegTrans_1000_2500.csv', 'DRG_2_SegTrans_1000_2500.jpg'), ('DRG_1_SegTrans_3000_2500.csv', 'DRG_1_SegTrans_3000_2500.jpg'), ('DRG_2_SegTrans_500_2500.csv', 'DRG_2_SegTrans_500_2500.jpg'), ('DRG_1_SegTrans_1000_1000.csv', 'DRG_1_SegTrans_1000_1000.jpg'), ('DRG_1_SegTrans_2000_3000.csv', 'DRG_1_SegTrans_2000_3000.jpg'), ('DRG_1_SegTrans_2000_2000.csv', 'DRG_1_SegTrans_2000_2000.jpg'), ('DRG_1_SegTrans_2000_1000.csv', 'DRG_1_SegTrans_2000_1000.jpg'), ('DRG_3_SegTrans_1000_2000.csv', 'DRG_3_SegTrans_1000_2000.jpg'), ('DRG_3_SegTrans_3000_2000.csv', 'DRG_3_SegTrans_3000_2000.jpg'), ('DRG_1_SegTrans_2500_1000.csv', 'DRG_1_SegTrans_2500_1000.jpg'), ('DRG_1_SegTrans_2500_500.csv', 'DRG_1_SegTrans_2500_500.jpg'), ('DRG_1_SegTrans_2500_2000.csv', 'DRG_1_SegTrans_2500_2000.jpg'), ('DRG_3_SegTrans_500_1500.csv', 'DRG_3_SegTrans_500_1500.jpg'), ('DRG_1_SegTrans_2500_1500.csv', 'DRG_1_SegTrans_2500_1500.jpg'), ('DRG_2_SegTrans_500_2000.csv', 'DRG_2_SegTrans_500_2000.jpg'), ('DRG_2_SegTrans_1000_2000.csv', 'DRG_2_SegTrans_1000_2000.jpg'), ('DRG_2_SegTrans_1500_2500.csv', 'DRG_2_SegTrans_1500_2500.jpg'), ('DRG_3_SegTrans_2000_2500.csv', 'DRG_3_SegTrans_2000_2500.jpg'), ('DRG_2_SegTrans_1000_3000.csv', 'DRG_2_SegTrans_1000_3000.jpg'), ('DRG_2_SegTrans_1000_3500.csv', 'DRG_2_SegTrans_1000_3500.jpg'), ('DRG_3_SegTrans_2500_2500.csv', 'DRG_3_SegTrans_2500_2500.jpg'), ('DRG_3_SegTrans_1000_1000.csv', 'DRG_3_SegTrans_1000_1000.jpg'), ('DRG_1_SegTrans_1500_1000.csv', 'DRG_1_SegTrans_1500_1000.jpg'), ('DRG_1_SegTrans_3000_2000.csv', 'DRG_1_SegTrans_3000_2000.jpg'), ('DRG_3_SegTrans_2000_1500.csv', 'DRG_3_SegTrans_2000_1500.jpg'), ('DRG_3_SegTrans_500_1000.csv', 'DRG_3_SegTrans_500_1000.jpg'), ('DRG_1_SegTrans_1500_2000.csv', 'DRG_1_SegTrans_1500_2000.jpg'), ('DRG_1_SegTrans_1000_3000.csv', 'DRG_1_SegTrans_1000_3000.jpg'), ('DRG_3_SegTrans_500_2500.csv', 'DRG_3_SegTrans_500_2500.jpg'), ('DRG_3_SegTrans_1500_1500.csv', 'DRG_3_SegTrans_1500_1500.jpg'), ('DRG_3_SegTrans_2000_2000.csv', 'DRG_3_SegTrans_2000_2000.jpg')]\n",
      "Default advanced parameters enabled\n",
      "!! WARNING: transDRG123_5masks_RN2_cyto2 already exists and will be deleted in the following cell !!\n",
      "2025-05-25 13:39:01,791 [INFO] WRITING LOG OUTPUT TO /home/yhs/.cellpose/run.log\n",
      "2025-05-25 13:39:01,792 [INFO] \n",
      "cellpose version: \t3.1.0 \n",
      "platform:       \tlinux \n",
      "python version: \t3.8.12 \n",
      "torch version:  \t2.3.1+cu121\n",
      "2025-05-25 13:39:01,793 [INFO] >> cyto2 << model set to be used\n",
      "2025-05-25 13:39:01,794 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2025-05-25 13:39:01,795 [INFO] >>>> using GPU (CUDA)\n",
      "2025-05-25 13:39:01,854 [INFO] >>>> loading model /home/yhs/.cellpose/models/cyto2torch_0\n",
      "2025-05-25 13:39:01,909 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n",
      "2025-05-25 13:39:01,919 [INFO] not all flows are present, running flow generation for all images\n",
      "2025-05-25 13:39:02,191 [INFO] 49 / 49 images in /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123/UnremovedTranscripts/Train folder have labels\n",
      "2025-05-25 13:39:02,195 [INFO] not all flows are present, running flow generation for all images\n",
      "2025-05-25 13:39:02,236 [INFO] 8 / 8 images in /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123/UnremovedTranscripts/Test folder have labels\n",
      "2025-05-25 13:39:02,237 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 49/49 [00:02<00:00, 22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-25 13:39:04,412 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-25 13:39:04,759 [INFO] >>> computing diameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 49/49 [00:00<00:00, 1225.35it/s]\n",
      "100%|███████████████████████████████████████████| 8/8 [00:00<00:00, 1104.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-25 13:39:04,813 [INFO] >>> using channels [1, 0]\n",
      "2025-05-25 13:39:04,814 [INFO] >>> normalizing {'lowhigh': None, 'percentile': None, 'normalize': True, 'norm3D': True, 'sharpen_radius': 0, 'smooth_radius': 0, 'tile_norm_blocksize': 0, 'tile_norm_smooth3D': 1, 'invert': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-25 13:39:05,251 [INFO] >>> n_epochs=100, n_train=49, n_test=8\n",
      "2025-05-25 13:39:05,253 [INFO] >>> SGD, learning_rate=0.10000, weight_decay=0.00010, momentum=0.900\n",
      "2025-05-25 13:39:05,258 [INFO] >>> saving model to /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123/UnremovedTranscripts/Train/models/transDRG123_5masks_RN2_cyto2\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1812/382999045.py\u001b[0m in \u001b[0;36m<cell line: 194>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mnimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     new_model_path = train.train_seg(model.net, train_data=train_data,\n\u001b[0m\u001b[1;32m    343\u001b[0m                                   \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                                   \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/cellpose/train.py\u001b[0m in \u001b[0;36mtrain_seg\u001b[0;34m(net, train_data, train_labels, train_files, train_labels_files, train_probs, test_data, test_labels, test_files, test_labels_files, test_probs, load_files, batch_size, learning_rate, n_epochs, weight_decay, momentum, SGD, channels, channel_axis, rgb, normalize, compute_flows, save_path, save_every, save_each, nimg_per_epoch, nimg_test_per_epoch, rescale, scale_range, bsize, min_train_masks, model_name)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# network and loss optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_loss_fn_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/cellpose/resnet_torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkldnn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_mkldnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mT0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkldnn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/cellpose/resnet_torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mxd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/cellpose/resnet_torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "#Inputs: List of initial models to use, desired image folder (H&E vs UnremovedTranscripts), drg4 image path, manual drg4 path\n",
    "#Outputs: Metrics csvs corresponding to each trained model\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from read_roi import read_roi_file, read_roi_zip\n",
    "from cellpose import core, utils, io, models, metrics, plot, train\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Optional: for PyTorch-based models (Cellpose may use this internally)\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "%run /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Finalized\\ Code/Training/evaluationPipeline.ipynb\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "\n",
    "#Original Directory\n",
    "base_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123'\n",
    "\n",
    "#initial_model = 'CPx'\n",
    "initial_model = 'cyto2'\n",
    "\n",
    "#'H&EStain' or 'UnremovedTranscripts'\n",
    "img_folder = 'UnremovedTranscripts'\n",
    "txt_folder = 'UnremovedTranscriptsTxt'\n",
    "min_masks = 5\n",
    "c1 = \"Red\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "c2_list = [\"None\", \"Green\"] #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "#@markdown threshold on flow error to accept a mask (set higher to get more cells, e.g. in range from (0.1, 3.0), OR set to 0.0 to turn off so no cells discarded):\n",
    "flow_threshold = 0.4 #@param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
    "#@markdown threshold on cellprob output to seed cell masks (set lower to include more pixels or higher to include fewer, e.g. in range from (-6, 6)):\n",
    "cellprob_threshold = 0 #@param {type:\"slider\", min:-6, max:6, step:1}\n",
    "\n",
    "def extracting_rois(file_path, img_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "    rois = []\n",
    "    img = Image.open(img_path)\n",
    "    width, height = img.size\n",
    "    for i in lines:\n",
    "        rois.append(list(map(float, i.split())))\n",
    "    rois_filtered = []\n",
    "    for i in rois:\n",
    "        rois_filtered.append(i[1:])\n",
    "    int_rois = []\n",
    "    for i in rois_filtered:\n",
    "        count = 0\n",
    "        x = []\n",
    "        y = []\n",
    "        for j in i:\n",
    "            if count%2:\n",
    "                x.append(int(round(j*width)))\n",
    "            else:\n",
    "                y.append(int(round(j*height)))\n",
    "            count += 1\n",
    "        temp = list(zip(x, y))\n",
    "        filt = []\n",
    "        for i in temp:\n",
    "            if i not in filt:\n",
    "                filt.append(i)\n",
    "        int_rois.append(filt)\n",
    "    return int_rois\n",
    "\n",
    "def save_rois_with_conversion(masks, files, output_dir):\n",
    "    # Ensure all masks are in the correct format\n",
    "    masks = [mask.astype(np.uint16) if mask.dtype != np.uint16 else mask for mask in masks]\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    count = 0\n",
    "    for file, mask in zip(files, masks):\n",
    "        count += 1\n",
    "        output_path = os.path.join(output_dir, file.split('/')[-1].replace('.jpg',''))\n",
    "        io.save_rois(mask, output_path)\n",
    "\n",
    "def zip_to_csv(directory):\n",
    "    for filename in [i for i in os.listdir(directory) if '.zip' in i]:\n",
    "        df_data = {'Name': [], 'X': [], 'Y': []}\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        data = read_roi_zip(file_path)\n",
    "        for name, roi in data.items():\n",
    "            df_data['X'].extend(roi['x'])\n",
    "            df_data['Y'].extend(roi['y'])\n",
    "            for i in range(len(roi['x'])):\n",
    "                df_data['Name'].append(str(roi['name']))\n",
    "        df = pd.DataFrame.from_dict(df_data)\n",
    "        out_dir = os.path.join(directory, 'csv')\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        df.to_csv(os.path.join(out_dir, filename).replace('.zip','.csv').replace('_rois','').replace('Nonseg','Seg'), sep=',', index=False, header=True)\n",
    "\n",
    "def csv_png(filename, height, width):\n",
    "    rois = pd.read_csv(filename)\n",
    "    image_height = height\n",
    "    image_width = width\n",
    "    grouped_rois = rois.groupby('Name')\n",
    "    count = 1\n",
    "    masks = []\n",
    "    for id, group in grouped_rois:\n",
    "        single_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "        polygon = [(x, y) for x, y in zip(group['X'], group['Y'])]\n",
    "        pts = np.array(polygon, dtype=np.int32)\n",
    "        pts = pts.reshape((-1, 1, 2))\n",
    "        cv2.fillPoly(single_mask, [pts], color=count)\n",
    "        masks.append(single_mask)\n",
    "        count += 1\n",
    "    if len(masks) == 0:\n",
    "        return np.zeros((width, height), dtype=np.uint16)\n",
    "    masks_array = np.stack(masks, axis=0)\n",
    "    combined = np.max(masks_array, axis = 0)\n",
    "    return combined\n",
    "\n",
    "def folder_mapping(i_dir, j_dir):\n",
    "    aligned = []\n",
    "    for i in os.listdir(i_dir):\n",
    "        for j in os.listdir(j_dir):\n",
    "            if i.split()[0] == j.split()[0]:\n",
    "                aligned.append((i, j))\n",
    "    return aligned\n",
    "\n",
    "def list_mapping(i_dir, j_dir):\n",
    "    aligned = []\n",
    "    for i in i_dir:\n",
    "        for j in j_dir:\n",
    "            if i.split('.')[0] == j.split('.')[0]:\n",
    "                aligned.append((i, j))\n",
    "            elif re.findall(r'\\d+', i) == re.findall(r'\\d+', j):\n",
    "                aligned.append((i, j))\n",
    "    print(aligned)\n",
    "    return aligned\n",
    "\n",
    "def check_unused_img(un_dir, u_dir, min_masks):\n",
    "    for maskname in [i for i in os.listdir(un_dir) if '_masks' in i]:\n",
    "        m_path = os.path.join(un_dir, maskname)\n",
    "        marr = np.array(Image.open(m_path))\n",
    "        num_masks = np.max(marr)\n",
    "        if num_masks >= min_masks:\n",
    "            os.rename(m_path, os.path.join(u_dir, maskname))\n",
    "            os.rename(m_path.replace('_masks.png', '.jpg'), os.path.join(u_dir, maskname.replace('_masks.png', '.jpg')))\n",
    "\n",
    "def check_unused_csv(un_dir, u_dir, min_masks):\n",
    "    for csvname in [i for i in os.listdir(un_dir) if '.csv' in i]:\n",
    "        c_path = os.path.join(un_dir, csvname)\n",
    "        csv = pd.read_csv(c_path)\n",
    "        if len(csv.groupby('Name')) >= min_masks:\n",
    "            os.rename(c_path, os.path.join(u_dir, csvname))\n",
    "            os.rename(c_path.replace('.csv', '.txt'), os.path.join(u_dir, csvname.replace('.csv', '.txt')))\n",
    "\n",
    "def add_unused_csv(un_dir, u_dir, min_masks):\n",
    "    for csvname in [i for i in os.listdir(u_dir) if '.csv' in i]:\n",
    "        c_path = os.path.join(u_dir, csvname)\n",
    "        csv = pd.read_csv(c_path)\n",
    "        if len(csv.groupby('Name')) < min_masks:\n",
    "            os.rename(c_path, os.path.join(un_dir, csvname))\n",
    "            os.rename(c_path.replace('.csv', '.txt'), os.path.join(un_dir, csvname.replace('.csv', '.txt')))\n",
    "\n",
    "def add_unused_img(un_dir, u_dir, min_masks):\n",
    "    for maskname in [i for i in os.listdir(u_dir) if '_masks' in i]:\n",
    "        m_path = os.path.join(u_dir, maskname)\n",
    "        marr = np.array(Image.open(m_path))\n",
    "        num_masks = np.max(marr)\n",
    "        if num_masks < min_masks:\n",
    "            os.rename(m_path, os.path.join(un_dir, maskname))\n",
    "            os.rename(m_path.replace('_masks.png', '.jpg'), os.path.join(un_dir, maskname.replace('_masks.png', '.jpg')))\n",
    "\n",
    "def manage_unused(ui_dir, i_dir, uf_dir, f_dir, min_masks):\n",
    "    add_unused_img(ui_dir, i_dir, min_masks)\n",
    "    add_unused_csv(uf_dir, f_dir, min_masks)\n",
    "    check_unused_img(ui_dir, i_dir, min_masks)\n",
    "    check_unused_csv(uf_dir, f_dir, min_masks)\n",
    "    \n",
    "for i in c2_list:\n",
    "    c2 = i\n",
    "    \n",
    "    if img_folder == 'H&EStain':\n",
    "        model_name = \"heDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'2_'+initial_model\n",
    "    else:\n",
    "        model_name = \"transDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'2_'+initial_model\n",
    "    \n",
    "    train_dir = os.path.join(base_dir, img_folder, 'Train')\n",
    "    test_dir = os.path.join(base_dir, img_folder, 'Test')\n",
    "    \n",
    "    if img_folder == 'H&EStain':\n",
    "        eval_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/DRG4HeImg'\n",
    "        pred_path = eval_dir + '/csv/drg4.csv'\n",
    "        man_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Xenium_segementation/ManuscriptProject/Scaled_DRG_Manual_Annotations/drg4_manual_scaled.csv'\n",
    "        out_path_drg4 = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Channel Comparison/he/drg4/'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'drg4.csv'\n",
    "        out_path_test = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Channel Comparison/he/test/'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'test.csv'\n",
    "        heat_map_out_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Default Prob Maps/he_trained_'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'drg4.tif'\n",
    "    else:\n",
    "        eval_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/TransDRG4'\n",
    "        pred_path = eval_dir + '/csv/croppedDRG4.csv'\n",
    "        man_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/ManualDRG4/drg4manual.csv'\n",
    "        out_path_drg4 = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Channel Comparison/trans/drg4/'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'drg4.csv'\n",
    "        out_path_test = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Channel Comparison/trans/test/'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'test.csv'\n",
    "        heat_map_out_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Default Prob Maps/trans_trained_'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'drg4.tif'\n",
    "    \n",
    "    #RUN THIS CELL TO INITIALIZE ALL REQUIRED FILES\n",
    "    \n",
    "    directory = os.path.join(base_dir, txt_folder)\n",
    "    folders = [os.path.join(directory, entry) for entry in os.listdir(directory) if os.path.isdir(os.path.join(directory, entry))]\n",
    "    \n",
    "    for folder in folders:\n",
    "        f_dir = os.pa th.join(directory, folder)\n",
    "        i_dir = f_dir.replace(txt_folder, img_folder)\n",
    "        ui_dir = os.path.join(i_dir, 'unused')\n",
    "        uf_dir = os.path.join(f_dir, 'unused')\n",
    "        os.makedirs(ui_dir, exist_ok=True)\n",
    "        os.makedirs(uf_dir, exist_ok=True)\n",
    "        for filename, imgname in list_mapping([i for i in os.listdir(f_dir) if '.txt' in i], [j for j in os.listdir(i_dir) if '.jpg' in j]):\n",
    "            file_path = os.path.join(f_dir, filename)\n",
    "            img_path = os.path.join(i_dir, imgname)\n",
    "            data = extracting_rois(file_path, img_path)\n",
    "            df = {'Name': [], 'X': [], 'Y': []}\n",
    "            count = 1\n",
    "            for i in data:\n",
    "                df['Name'].extend(['roi'+str(count) for j in i])\n",
    "                df['X'].extend([k for j, k in i])\n",
    "                df['Y'].extend([j for j, k in i])\n",
    "                count += 1\n",
    "            df_csv = pd.DataFrame(df)\n",
    "            df_csv.to_csv(os.path.join(f_dir, filename.replace('.txt','.csv')))\n",
    "        for filename, imgname in list_mapping([i for i in os.listdir(f_dir) if '.csv' in i], [j for j in os.listdir(i_dir) if '.jpg' in j]):\n",
    "            file_path = os.path.join(f_dir, filename)\n",
    "            img_path = os.path.join(i_dir, imgname)\n",
    "            imarr = csv_png(file_path, 500, 500)\n",
    "            im = Image.fromarray(imarr)\n",
    "            im.save(os.path.join(img_path.replace('.jpg','_masks.png')))\n",
    "    \n",
    "    #FILTERS NEW CELLS\n",
    "    for folder in folders:\n",
    "        f_dir = os.path.join(directory, folder)\n",
    "        i_dir = f_dir.replace(txt_folder, img_folder)\n",
    "        ui_dir = os.path.join(i_dir, 'unused')\n",
    "        uf_dir = os.path.join(f_dir, 'unused')\n",
    "        manage_unused(ui_dir, i_dir, uf_dir, f_dir, min_masks)\n",
    "    \n",
    "    # other parameters for training.\n",
    "    #@markdown ###Training Parameters:\n",
    "    #@markdown Number of epochs:\n",
    "    n_epochs =  100#@param {type:\"number\"}\n",
    "    \n",
    "    Channel_to_use_for_training = c1 #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "    Second_training_channel= c2 #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    #@markdown ###Advanced Parameters\n",
    "    \n",
    "    Use_Default_Advanced_Parameters = True #@param {type:\"boolean\"}\n",
    "    #@markdown ###If not, please input:\n",
    "    learning_rate = 0.1 #@param {type:\"number\"}\n",
    "    weight_decay = 0.0001 #@param {type:\"number\"}\n",
    "    \n",
    "    if (Use_Default_Advanced_Parameters):\n",
    "      print(\"Default advanced parameters enabled\")\n",
    "      learning_rate = 0.1\n",
    "      weight_decay = 0.0001\n",
    "    \n",
    "    #here we check that no model with the same name already exist, if so delete\n",
    "    model_path = train_dir + '/models'\n",
    "    if os.path.exists(model_path+'/'+model_name):\n",
    "      print(\"!! WARNING: \"+model_name+\" already exists and will be deleted in the following cell !!\")\n",
    "    \n",
    "    if len(test_dir) == 0:\n",
    "      test_dir = None\n",
    "    \n",
    "    # Here we match the channel to number\n",
    "    if Channel_to_use_for_training == \"Grayscale\":\n",
    "      chan = 0\n",
    "    elif Channel_to_use_for_training == \"Blue\":\n",
    "      chan = 3\n",
    "    elif Channel_to_use_for_training == \"Green\":\n",
    "      chan = 2\n",
    "    elif Channel_to_use_for_training == \"Red\":\n",
    "      chan = 1\n",
    "    \n",
    "    \n",
    "    if Second_training_channel == \"Blue\":\n",
    "      chan2 = 3\n",
    "    elif Second_training_channel == \"Green\":\n",
    "      chan2 = 2\n",
    "    elif Second_training_channel == \"Red\":\n",
    "      chan2 = 1\n",
    "    elif Second_training_channel == \"None\":\n",
    "      chan2 = 0\n",
    "    \n",
    "    if initial_model=='scratch':\n",
    "      initial_model = 'None'\n",
    "        \n",
    "    \n",
    "    # start logger (to see training across epochs)\n",
    "    logger = io.logger_setup()\n",
    "    \n",
    "    # DEFINE CELLPOSE MODEL (without size model)\n",
    "    model = models.CellposeModel(gpu=use_GPU, model_type=initial_model)\n",
    "    \n",
    "    # set channels\n",
    "    channels = [chan, chan2]\n",
    "    \n",
    "    # get files\n",
    "    output = io.load_train_test_data(train_dir, test_dir, mask_filter='_masks')\n",
    "    train_data, train_labels, _, test_data, test_labels, _ = output\n",
    "    \n",
    "    nimg = len(train_data)\n",
    "    \n",
    "    new_model_path = train.train_seg(model.net, train_data=train_data,\n",
    "                                  train_labels=train_labels,\n",
    "                                  test_data=test_data,\n",
    "                                  test_labels=test_labels,\n",
    "                                  channels=channels,\n",
    "                                  save_path=train_dir,\n",
    "                                  n_epochs=n_epochs,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  weight_decay=weight_decay,\n",
    "                                  SGD=True,                            \n",
    "                                  nimg_per_epoch=8,\n",
    "                                  min_train_masks=min_masks,\n",
    "                                  model_name=model_name)\n",
    "    \n",
    "    # diameter of labels in training images\n",
    "    diam_labels = model.net.diam_labels.item()\n",
    "    \n",
    "    # get files (during training, test_data is transformed so we will load it again)\n",
    "    output = io.load_train_test_data(test_dir, mask_filter='_masks')\n",
    "    test_data, test_labels = output[:2]\n",
    "        \n",
    "    # run model on test images\n",
    "    masks = model.eval(test_data,\n",
    "                       channels=[chan, chan2],\n",
    "                       diameter=diam_labels)[0]\n",
    "    \n",
    "    # check performance using ground truth labels\n",
    "    ap = metrics.average_precision(test_labels, masks)[0]\n",
    "\n",
    "    print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n",
    "    \n",
    "    print(diam_labels)\n",
    "    \n",
    "    # model name and path\n",
    "    \n",
    "    #@markdown ###Custom model path (full path):\n",
    "    \n",
    "    model_path = os.path.join(train_dir, 'models', model_name)\n",
    "    \n",
    "    #@markdown ###Path to images:\n",
    "    \n",
    "    dir = eval_dir #@param {type:\"string\"}\n",
    "    \n",
    "    #@markdown ###Channel Parameters:\n",
    "    \n",
    "    Channel_to_use_for_segmentation = c1 #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    # @markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
    "    \n",
    "    Second_segmentation_channel= c2 #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    \n",
    "    # Here we match the channel to number\n",
    "    if Channel_to_use_for_segmentation == \"Grayscale\":\n",
    "      chan = 0\n",
    "    elif Channel_to_use_for_segmentation == \"Blue\":\n",
    "      chan = 3\n",
    "    elif Channel_to_use_for_segmentation == \"Green\":\n",
    "      chan = 2\n",
    "    elif Channel_to_use_for_segmentation == \"Red\":\n",
    "      chan = 1\n",
    "    \n",
    "    \n",
    "    if Second_segmentation_channel == \"Blue\":\n",
    "      chan2 = 3\n",
    "    elif Second_segmentation_channel == \"Green\":\n",
    "      chan2 = 2\n",
    "    elif Second_segmentation_channel == \"Red\":\n",
    "      chan2 = 1\n",
    "    elif Second_segmentation_channel == \"None\":\n",
    "      chan2 = 0\n",
    "    \n",
    "    #@markdown ### Segmentation parameters:\n",
    "    \n",
    "    #@markdown diameter of cells (set to zero to use diameter from training set):\n",
    "    diameter =  diam_labels #@param {type:\"number\"}\n",
    "    \n",
    "    \n",
    "    # gets image files in dir (ignoring image files ending in _masks)\n",
    "    files = io.get_image_files(dir, '_masks')\n",
    "    images = [io.imread(f) for f in files]\n",
    "    \n",
    "    # declare model\n",
    "    model = models.CellposeModel(gpu=True,\n",
    "                                 pretrained_model=model_path)\n",
    "    \n",
    "    # use model diameter if user diameter is 0\n",
    "    diameter = model.diam_labels if diameter==0 else diameter\n",
    "    \n",
    "    # run model on test images\n",
    "    masks, flows, styles = model.eval(images,\n",
    "                                      channels=[chan, chan2],\n",
    "                                      diameter=diameter,\n",
    "                                      flow_threshold=flow_threshold,\n",
    "                                      cellprob_threshold=cellprob_threshold\n",
    "                                      )\n",
    "    \n",
    "    io.masks_flows_to_seg(images,\n",
    "                          masks,\n",
    "                          flows,\n",
    "                          files,\n",
    "                          channels=[chan, chan2],\n",
    "                          diams=diameter*np.ones(len(masks)),\n",
    "                          )\n",
    "    \n",
    "    save_rois_with_conversion(masks, files, eval_dir)\n",
    "    \n",
    "    zip_to_csv(eval_dir)\n",
    "    \n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'DRG4 Eval Complete in {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if img_folder == 'H&EStain':\n",
    "        performance = optimized_model_eval_files(man_path, pred_path)\n",
    "    else:\n",
    "        performance = optimized_model_eval_files(man_path, pred_path)\n",
    "    \n",
    "    df_csv = pd.DataFrame.from_dict(performance)\n",
    "    df_csv.to_csv(out_path_drg4)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time-start_time\n",
    "    \n",
    "    plt.figure(figsize=(8, 10))\n",
    "    plt.imshow(flows[0][2], cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label='Intensity')\n",
    "    plt.title('Heatmap Visualization')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.show()\n",
    "    plt.savefig(heat_map_out_path)\n",
    "    \n",
    "    print(f'Eval Pipeline Complete in {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    # model name and path\n",
    "    #duplicate the test folder and label it manual\n",
    "    \n",
    "    man_dir_1 = os.path.join(base_dir, txt_folder, 'Test')\n",
    "    eval_dir_1 = test_dir.replace('Test', 'Eval')\n",
    "    if os.path.isdir(eval_dir_1):\n",
    "        shutil.rmtree(eval_dir_1)\n",
    "    shutil.copytree(test_dir, eval_dir_1)\n",
    "    \n",
    "    print(txt_folder)\n",
    "    \n",
    "    eu_dir = os.path.join(eval_dir_1, 'unused')\n",
    "    tt_dir = os.path.join(base_dir, txt_folder, 'Test')\n",
    "    utt_dir = os.path.join(tt_dir, 'unused')\n",
    "    manage_unused(eu_dir, eval_dir_1, utt_dir, tt_dir, 0)\n",
    "    \n",
    "    #@markdown ###Custom model path (full path):\n",
    "    \n",
    "    model_path = os.path.join(train_dir, 'models', model_name)\n",
    "    \n",
    "    #@markdown ###Path to images:\n",
    "    \n",
    "    dir = eval_dir_1 #@param {type:\"string\"}\n",
    "    \n",
    "    #@markdown ###Channel Parameters:\n",
    "    \n",
    "    Channel_to_use_for_segmentation = c1 #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    # @markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
    "    \n",
    "    Second_segmentation_channel= c2 #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    \n",
    "    # Here we match the channel to number\n",
    "    if Channel_to_use_for_segmentation == \"Grayscale\":\n",
    "      chan = 0\n",
    "    elif Channel_to_use_for_segmentation == \"Blue\":\n",
    "      chan = 3\n",
    "    elif Channel_to_use_for_segmentation == \"Green\":\n",
    "      chan = 2\n",
    "    elif Channel_to_use_for_segmentation == \"Red\":\n",
    "      chan = 1\n",
    "    \n",
    "    \n",
    "    if Second_segmentation_channel == \"Blue\":\n",
    "      chan2 = 3\n",
    "    elif Second_segmentation_channel == \"Green\":\n",
    "      chan2 = 2\n",
    "    elif Second_segmentation_channel == \"Red\":\n",
    "      chan2 = 1\n",
    "    elif Second_segmentation_channel == \"None\":\n",
    "      chan2 = 0\n",
    "    \n",
    "    #@markdown ### Segmentation parameters:\n",
    "    \n",
    "    #@markdown diameter of cells (set to zero to use diameter from training set):\n",
    "    diameter =  diam_labels #@param {type:\"number\"}\n",
    "    \n",
    "    \n",
    "    # gets image files in dir (ignoring image files ending in _masks)\n",
    "    files = io.get_image_files(dir, '_masks')\n",
    "    images = [io.imread(f) for f in files]\n",
    "    \n",
    "    # declare model\n",
    "    model = models.CellposeModel(gpu=True,\n",
    "                                 pretrained_model=model_path)\n",
    "    \n",
    "    # use model diameter if user diameter is 0\n",
    "    diameter = model.diam_labels if diameter==0 else diameter\n",
    "    \n",
    "    # run model on test images\n",
    "    masks, flows, styles = model.eval(images,\n",
    "                                      channels=[chan, chan2],\n",
    "                                      diameter=diameter,\n",
    "                                      flow_threshold=flow_threshold,\n",
    "                                      cellprob_threshold=cellprob_threshold\n",
    "                                      )\n",
    "    \n",
    "    io.masks_flows_to_seg(images,\n",
    "                          masks,\n",
    "                          flows,\n",
    "                          files,\n",
    "                          channels=[chan, chan2],\n",
    "                          diams=diameter*np.ones(len(masks)),\n",
    "                          )\n",
    "    \n",
    "    save_rois_with_conversion(masks, files, eval_dir_1)\n",
    "    \n",
    "    zip_to_csv(eval_dir_1)\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(man_dir_1, 'csv')):\n",
    "        zip_to_csv(man_dir_1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Test Folder Eval Complete in {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    performance_1 = optimized_model_eval(man_dir_1, os.path.join(eval_dir_1, 'csv'))\n",
    "    \n",
    "    df_csv = pd.DataFrame.from_dict(performance_1)\n",
    "    df_csv.to_csv(out_path_test)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time-start_time\n",
    "    \n",
    "    print(f'Eval Pipeline Complete in {elapsed_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e33aed0-5996-4865-a5ca-f1c62617d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25eae5-0aa9-4b2d-90a1-1506075f66b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
