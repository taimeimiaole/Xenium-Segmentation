{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbf7bbb-b643-4cdc-bd66-a86ad6ab9476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? YES\n",
      "Ready\n",
      "transDRG123_18masks_RN2\n",
      "/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123/UnremovedTranscripts/Train/models/transDRG123_18masks_RN2\n",
      "starting test evaluation\n",
      "done\n",
      "        Unnamed: 0    Name     X     Y\n",
      "0                0    roi0   892  1795\n",
      "1                1    roi0   891  1796\n",
      "2                2    roi0   891  1796\n",
      "3                3    roi0   891  1796\n",
      "4                4    roi0   891  1796\n",
      "...            ...     ...   ...   ...\n",
      "137445      137445  roi305  1754   807\n",
      "137446      137446  roi305  1753   806\n",
      "137447      137447  roi305  1753   806\n",
      "137448      137448  roi305  1753   806\n",
      "137449      137449  roi305  1753   806\n",
      "\n",
      "[137450 rows x 4 columns]\n",
      "Manual conversion\n",
      "Polygon for ROI \"4\" is invalid: Self-intersection[1257 2600].\n",
      "[<POLYGON ((1265 2578, 1264 2578, 1263 2578, 1263 2577, 1262 2577, 1261 2577,...>]\n",
      "Polygon for ROI \"22\" is invalid: Ring Self-intersection[2012 1610].\n",
      "[<POLYGON ((2011 1610, 2010 1610, 2009 1610, 2009 1611, 2008 1611, 2008 1612,...>]\n",
      "Polygon for ROI \"26\" is invalid: Ring Self-intersection[1174 2609].\n",
      "[<POLYGON ((1157 2544, 1156 2544, 1156 2545, 1156 2546, 1155 2547, 1155 2548,...>]\n",
      "Polygon for ROI \"31\" is invalid: Ring Self-intersection[1599 987].\n",
      "[<POLYGON ((1599 986, 1598 985, 1598 984, 1597 983, 1597 982, 1597 981, 1597 ...>]\n",
      "Polygon for ROI \"37\" is invalid: Ring Self-intersection[1244 165].\n",
      "[<POLYGON ((1243 165, 1242 165, 1241 165, 1240 165, 1239 165, 1239 166, 1238 ...>]\n",
      "Polygon for ROI \"82\" is invalid: Ring Self-intersection[1164 2502].\n",
      "[<POLYGON ((1165 2502, 1166 2502, 1167 2501, 1168 2501, 1168 2500, 1169 2500,...>]\n",
      "Polygon for ROI \"85\" is invalid: Ring Self-intersection[998 2311].\n",
      "[<POLYGON ((997 2310, 997 2309, 996 2309, 995 2309, 994 2309, 994 2308, 993 2...>]\n",
      "Polygon for ROI \"86\" is invalid: Ring Self-intersection[778 420].\n",
      "[<POLYGON ((778 421, 779 421, 779 422, 780 422, 781 422, 781 423, 782 423, 78...>]\n",
      "Polygon for ROI \"131\" is invalid: Ring Self-intersection[962 2238].\n",
      "[<POLYGON ((948 2227, 947 2227, 946 2227, 946 2228, 945 2228, 944 2228, 943 2...>]\n",
      "Polygon for ROI \"161\" is invalid: Ring Self-intersection[1116 2203].\n",
      "[<POLYGON ((1115 2203, 1114 2203, 1114 2204, 1113 2205, 1112 2206, 1112 2207,...>]\n",
      "Polygon for ROI \"231\" is invalid: Ring Self-intersection[2149 1920].\n",
      "[<POLYGON ((2158 1899, 2157 1899, 2156 1899, 2155 1899, 2154 1899, 2153 1899,...>]\n",
      "Polygon for ROI \"242\" is invalid: Ring Self-intersection[1731 1119].\n",
      "[<POLYGON ((1730 1099, 1729 1099, 1728 1100, 1727 1100, 1726 1100, 1726 1101,...>]\n",
      "Polygon for ROI \"281\" is invalid: Ring Self-intersection[1101 1518].\n",
      "[<POLYGON ((1140 1532, 1139 1532, 1139 1533, 1138 1533, 1137 1533, 1136 1533,...>]\n",
      "306\n",
      "306\n",
      "Prediction conversion\n",
      "Polygon for ROI \"114\" is invalid: Ring Self-intersection[1870 984].\n",
      "[<POLYGON ((1870 985, 1870 986, 1870 987, 1869 988, 1869 989, 1869 990, 1869 ...>]\n",
      "255\n",
      "255\n",
      "[0.8021390374331552]\n",
      "[0.5044563279857398]\n",
      "dict_keys(['Name', 'Total Area', 'Total Manual Masks', 'Valid Manual Masks', 'Total Predicted Masks', 'Valid Predicted Masks', 'List of Intersections', 'List of IoUs', 'AP50', 'mAP50-95', 'cell_prec50', 'cell_prec50-95', 'cell_rec50', 'cell_rec50-95', 'cell_f1_50', 'cell_f1_50-95', 'Total IoU', 'pix_prec', 'pix_rec', 'pix_f1', 'List of Relations'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flow Threshold Loop:   0%|                               | 0/30 [00:00<?, ?it/s]\n",
      "Prob Threshold Loop (flow=0.1):   0%|                    | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Flow Threshold Loop:   0%|                               | 0/30 [00:05<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8705/29872813.py\u001b[0m in \u001b[0;36m<cell line: 255>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;31m# Call the function with the necessary arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_flowprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchan2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Flow Prob/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_probflow_f1_50.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Flow Prob/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_probflow_f1_50_95.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8705/29872813.py\u001b[0m in \u001b[0;36moptimize_flowprob\u001b[0;34m(model, images, files, eval_dir, base_dir, txt_folder, diameter, chan, chan2)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# Save the segmentation results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             io.masks_flows_to_seg(\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/cellpose/io.py\u001b[0m in \u001b[0;36mmasks_flows_to_seg\u001b[0;34m(images, masks, flows, file_names, diams, channels, imgs_restore, restore_type, ratio)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchannels_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0mchannels_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             masks_flows_to_seg(image, mask, flow, file_name, diams=diam,\n\u001b[0m\u001b[1;32m    508\u001b[0m                                \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                                restore_type=restore_type, ratio=ratio)\n",
      "\u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/cellpose/io.py\u001b[0m in \u001b[0;36mmasks_flows_to_seg\u001b[0;34m(images, masks, flows, file_names, diams, channels, imgs_restore, restore_type, ratio)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_restore\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs_restore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_seg.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_to_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    523\u001b[0m                            pickle_kwargs=dict(fix_imports=fix_imports))\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Inputs: Range of minimum masks (hard coded to 35), pretrained model, desired image type folder, path to evaluation pipeline, drg4 path, manual drg4 path\n",
    "#Outputs: Folder of metrics csvs for every flow-prob threshold combination and three cumulative csvs of mAP50, mAP50-95 and all values recorded in the csvs\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics, plot\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from read_roi import read_roi_file\n",
    "from read_roi import read_roi_zip\n",
    "from cellpose import models\n",
    "from cellpose import train\n",
    "from cellpose import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Optional: for PyTorch-based models (Cellpose may use this internally)\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "%run /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Finalized\\ Code/Training/evaluationPipeline.ipynb\n",
    "\n",
    "def save_rois_with_conversion(masks, files, output_dir):\n",
    "    # Ensure all masks are in the correct format\n",
    "    masks = [mask.astype(np.uint8) if mask.dtype != np.uint8 else mask for mask in masks]\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    count = 0\n",
    "    for file, mask in zip(files, masks):\n",
    "        count += 1\n",
    "        output_path = os.path.join(output_dir, file.split('/')[-1].replace('.jpg',''))\n",
    "        io.save_rois(mask, output_path)\n",
    "\n",
    "def zip_to_csv(directory):\n",
    "    for filename in [i for i in os.listdir(directory) if '.zip' in i]:\n",
    "        df_data = {'Name': [], 'X': [], 'Y': []}\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        data = read_roi_zip(file_path)\n",
    "        for name, roi in data.items():\n",
    "            df_data['X'].extend(roi['x'])\n",
    "            df_data['Y'].extend(roi['y'])\n",
    "            for i in range(len(roi['x'])):\n",
    "                df_data['Name'].append(str(roi['name']))\n",
    "        df = pd.DataFrame.from_dict(df_data)\n",
    "        out_dir = os.path.join(directory, 'csv')\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        df.to_csv(os.path.join(out_dir, filename).replace('.zip','.csv').replace('_rois','').replace('Nonseg','Seg'), sep=',', index=False, header=True)\n",
    "\n",
    "def optimize_flowprob(model, images, files, eval_dir, base_dir, txt_folder, diameter, chan, chan2):\n",
    "    # Initialize variables\n",
    "    tdplot50 = {}\n",
    "    tdplot50_95 = {}\n",
    "    allVals = {}\n",
    "    \n",
    "    # Define prob and flow ranges\n",
    "    prob_values = np.arange(-6, 7)  # Prob values from -6 to 6\n",
    "    flow_values = np.arange(0.1, 3.1, 0.1)  # Flow values from 0 to 3 with a step of 0.1\n",
    "\n",
    "    # Total number of iterations for tqdm\n",
    "    total_iterations = len(flow_values) * len(prob_values)\n",
    "\n",
    "    # Iterate over flow and prob values with progress tracking\n",
    "    for flow in tqdm(flow_values, desc=\"Flow Threshold Loop\", position=0, leave=True):\n",
    "        for prob in tqdm(prob_values, desc=f\"Prob Threshold Loop (flow={flow})\", position=1, leave=False):\n",
    "            x = (flow, prob)\n",
    "\n",
    "            # Evaluate the model\n",
    "            masks, flows, styles = model.eval(\n",
    "                images,\n",
    "                channels=[chan, chan2],\n",
    "                diameter=diameter,\n",
    "                flow_threshold=flow,\n",
    "                cellprob_threshold=prob\n",
    "            )\n",
    "\n",
    "            # Save the segmentation results\n",
    "            io.masks_flows_to_seg(\n",
    "                images,\n",
    "                masks,\n",
    "                flows,\n",
    "                files,\n",
    "                channels=[chan, chan2],\n",
    "                diams=diameter * np.ones(len(masks)),\n",
    "            )\n",
    "\n",
    "            save_rois_with_conversion(masks, files, eval_dir)\n",
    "            zip_to_csv(eval_dir)\n",
    "\n",
    "            # Evaluate model performance\n",
    "            performance = optimized_model_eval_files(man_path, pred_path)\n",
    "            print(man_path, pred_path)\n",
    "            \n",
    "            # Store the F1-Score in the dictionary\n",
    "            tdplot50[x] = performance['cell_f1_50'][-1]\n",
    "            tdplot50_95[x] = performance['cell_f1_50-95'][-1]\n",
    "            excluded_keys = ['List of Intersections', 'List of IoUs']\n",
    "            filtered_performance = {k: v for k, v in performance.items() if k not in excluded_keys}\n",
    "            allVals[x] = filtered_performance\n",
    "\n",
    "    # Save results to CSV\n",
    "    res50 = pd.DataFrame.from_dict(tdplot50, orient='index', columns=['mAF50'])\n",
    "    res50_95 = pd.DataFrame.from_dict(tdplot50_95, orient='index', columns=['mAF50-95'])\n",
    "    allVals_df = pd.DataFrame.from_dict(allVals, orient='index')\n",
    "\n",
    "    return res50, res50_95, allVals_df\n",
    "\n",
    "#@markdown ###Path to images and masks:\n",
    "base_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123'\n",
    "\n",
    "#@markdown ###Path to images and masks:\n",
    "img_folder = 'UnremovedTranscripts'\n",
    "txt_folder = 'UnremovedTranscriptsTxt'\n",
    "min_masks = 18\n",
    "c1 = \"Red\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "c2 = \"None\" #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "if img_folder == 'H&EStain':\n",
    "    model_name = \"heDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'2'\n",
    "else:\n",
    "    model_name = \"transDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'2'\n",
    "print(model_name)\n",
    "#@markdown threshold on flow error to accept a mask (set higher to get more cells, e.g. in range from (0.1, 3.0), OR set to 0.0 to turn off so no cells discarded):\n",
    "flow_threshold = 0.4 #@param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
    "#@markdown threshold on cellprob output to seed cell masks (set lower to include more pixels or higher to include fewer, e.g. in range from (-6, 6)):\n",
    "cellprob_threshold = 0 #@param {type:\"slider\", min:-6, max:6, step:1}\n",
    "\n",
    "out_path = base_dir+'/cellpose_'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'.csv'\n",
    "\n",
    "# model name and path\n",
    "train_dir = os.path.join(base_dir, img_folder, 'Train')\n",
    "test_dir = os.path.join(base_dir, img_folder, 'Test')\n",
    "\n",
    "#here we check that no model with the same name already exist, if so delete\n",
    "model_path = os.path.join(train_dir, 'models', model_name)\n",
    "print(model_path)\n",
    "\n",
    "if img_folder == 'H&EStain':\n",
    "    eval_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/DRG Full Images/H&EStain/DRG4'\n",
    "    pred_path = eval_dir + '/csv/drg4.csv'\n",
    "    man_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Xenium_segementation/ManuscriptProject/Scaled_DRG_Manual_Annotations/drg4_manual_scaled.csv'\n",
    "else:\n",
    "    eval_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/TransDRG4'\n",
    "    pred_path = eval_dir + '/csv/croppedDRG4.csv'\n",
    "    man_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/ManualDRG4/drg4manual.csv'\n",
    "\n",
    "# model name and path\n",
    "\n",
    "#@markdown ###Custom model path (full path):\n",
    "\n",
    "#model_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123/H&EStain/Train/models/heDRG123_5masks_RN_pre'\n",
    "\n",
    "#@markdown ###Path to images:\n",
    "\n",
    "dir = eval_dir #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ###Channel Parameters:\n",
    "\n",
    "Channel_to_use_for_segmentation = c1 #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "# @markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
    "\n",
    "Second_segmentation_channel= c2 #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "\n",
    "# Here we match the channel to number\n",
    "if Channel_to_use_for_segmentation == \"Grayscale\":\n",
    "  chan = 0\n",
    "elif Channel_to_use_for_segmentation == \"Blue\":\n",
    "  chan = 3\n",
    "elif Channel_to_use_for_segmentation == \"Green\":\n",
    "  chan = 2\n",
    "elif Channel_to_use_for_segmentation == \"Red\":\n",
    "  chan = 1\n",
    "\n",
    "\n",
    "if Second_segmentation_channel == \"Blue\":\n",
    "  chan2 = 3\n",
    "elif Second_segmentation_channel == \"Green\":\n",
    "  chan2 = 2\n",
    "elif Second_segmentation_channel == \"Red\":\n",
    "  chan2 = 1\n",
    "elif Second_segmentation_channel == \"None\":\n",
    "  chan2 = 0\n",
    "\n",
    "#@markdown ### Segmentation parameters:\n",
    "\n",
    "#@markdown diameter of cells (set to zero to use diameter from training set):\n",
    "diameter =  0 #@param {type:\"number\"}\n",
    "\n",
    "\n",
    "# gets image files in dir (ignoring image files ending in _masks)\n",
    "files = io.get_image_files(dir, '_heatmap.tif')\n",
    "images = [io.imread(f) for f in files]\n",
    "\n",
    "# declare model\n",
    "model = models.CellposeModel(gpu=True,\n",
    "                             pretrained_model=model_path)\n",
    "\n",
    "# use model diameter if user diameter is 0\n",
    "diameter = model.diam_labels if diameter==0 else diameter\n",
    "\n",
    "print('starting test evaluation')\n",
    "# run model on test images\n",
    "masks, flows, styles = model.eval(images,\n",
    "                                  channels=[chan, chan2],\n",
    "                                  diameter=diameter,\n",
    "                                  flow_threshold=flow_threshold,\n",
    "                                  cellprob_threshold=cellprob_threshold\n",
    "                                  )\n",
    "\n",
    "from cellpose import io\n",
    "\n",
    "io.masks_flows_to_seg(images,\n",
    "                      masks,\n",
    "                      flows,\n",
    "                      files,\n",
    "                      channels=[chan, chan2],\n",
    "                      diams=diameter*np.ones(len(masks)),\n",
    "                      )\n",
    "\n",
    "save_rois_with_conversion(masks, files, eval_dir)\n",
    "\n",
    "zip_to_csv(eval_dir)\n",
    "\n",
    "print('done')\n",
    "\n",
    "performance = optimized_model_eval_files(man_path, pred_path)\n",
    "\n",
    "print(performance.keys())\n",
    "\n",
    "# Call the function with the necessary arguments\n",
    "res = optimize_flowprob(model, images, files, eval_dir, base_dir, txt_folder, diameter, chan, chan2)\n",
    "res[0].to_csv('/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Flow Prob/'+model_name+'_probflow_f1_50.csv')\n",
    "res[1].to_csv('/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Flow Prob/'+model_name+'_probflow_f1_50_95.csv')\n",
    "res[2].to_csv('/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Flow Prob/'+model_name+'_allVals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a538db4-1fdd-4cf0-a1bd-4a751e58dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CURRENTLY RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca243c8-b4c4-422f-8afd-e82179f727b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
