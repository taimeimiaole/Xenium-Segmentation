{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50bb2c6d-8bf8-43f7-bf6f-cb1297c224e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "#Inputs: Directory/path of raw manual csvs, directory/path of raw predicted csvs\n",
    "#Outputs: Metrics csv with precision, recall, f1, iou, and relation categorization metrics\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon, MultiPolygon, GeometryCollection\n",
    "from shapely.ops import unary_union\n",
    "from shapely.validation import explain_validity\n",
    "import os\n",
    "import re\n",
    "import chardet\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from skimage.measure import label, regionprops\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.validation import make_valid\n",
    "\n",
    "def read_csv_to_polygons_old(data):\n",
    "    rois = []\n",
    "    grouped = data.groupby('Name').agg(list).reset_index()\n",
    "    for _, row in grouped.iterrows():\n",
    "        outline = list(zip(row['X'], row['Y']))\n",
    "        if outline[0] != outline[-1]:\n",
    "            outline.append(outline[0])\n",
    "        polygon = Polygon(outline)\n",
    "        rois.append(polygon)\n",
    "    return rois\n",
    "\n",
    "def read_csv_to_polygons(data, visualize_invalid=True):\n",
    "    rois = []\n",
    "    grouped = data.groupby('Name').agg(list).reset_index()\n",
    "\n",
    "    for name, row in grouped.iterrows():\n",
    "        outline = list(zip(row['X'], row['Y']))\n",
    "\n",
    "        if len(outline) < 3:\n",
    "            continue\n",
    "\n",
    "        outline.append(outline[0])  # Close the loop\n",
    "\n",
    "        if len(outline) < 4:\n",
    "            continue\n",
    "\n",
    "        polygon = Polygon(outline)\n",
    "\n",
    "        if not polygon.is_valid:\n",
    "            reason = explain_validity(polygon)\n",
    "            print(f'Polygon for ROI \"{name}\" is invalid: {reason}.')\n",
    "            valid_geom = make_valid(polygon)\n",
    "\n",
    "            # Extract only Polygon parts\n",
    "            if isinstance(valid_geom, Polygon):\n",
    "                parts = [valid_geom]\n",
    "            elif isinstance(valid_geom, MultiPolygon):\n",
    "                parts = list(valid_geom.geoms)\n",
    "            elif isinstance(valid_geom, GeometryCollection):\n",
    "                parts = [g for g in valid_geom.geoms if isinstance(g, Polygon)]\n",
    "            else:\n",
    "                parts = []\n",
    "\n",
    "            if parts:\n",
    "                print(parts)\n",
    "                # Find the polygon with the largest area\n",
    "                largest_poly = max(parts, key=lambda p: p.area)\n",
    "                rois.append(largest_poly)\n",
    "\n",
    "            if visualize_invalid:\n",
    "                # Plot original\n",
    "                xs, ys = zip(*outline)\n",
    "                plt.figure(figsize=(5, 5))\n",
    "                plt.plot(xs, ys, marker='o', linestyle='-', label='Original (Invalid)')\n",
    "                plt.title(f'Invalid ROI: {name}\\nReason: {reason}')\n",
    "                plt.gca().set_aspect('equal', adjustable='box')\n",
    "                plt.grid(True)\n",
    "\n",
    "                # Plot fixed parts\n",
    "                valid_parts = []\n",
    "                for i, poly in enumerate(parts):\n",
    "                    x, y = poly.exterior.xy\n",
    "                    \n",
    "                    plt.plot(x, y, label=f'Valid Part {i+1}')\n",
    "\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "            continue\n",
    "\n",
    "        rois.append(polygon)\n",
    "\n",
    "    return rois, len(grouped)\n",
    "\n",
    "def list_of_intersections(l1, l2):\n",
    "    inter = [(p1, p2) for p1 in l1 for p2 in l2 if p1.intersects(p2) and not p1.touches(p2)]\n",
    "    return inter\n",
    "\n",
    "def best_iou_list(manual_rois, predicted_rois):\n",
    "    liou = []\n",
    "    for man in manual_rois:\n",
    "        max_iou = max([iou(man, pred) for pred in predicted_rois] or [0])\n",
    "        liou.append(max_iou)\n",
    "    return liou\n",
    "\n",
    "def intersect(l1, l2, loi):\n",
    "    inter = [p1.intersection(p2) for (p1, p2) in loi]\n",
    "    return inter\n",
    "\n",
    "def tot_iou(roi1, roi2, loi):\n",
    "    union = unary_union(roi1 + roi2)\n",
    "    inter = unary_union(intersect(roi1, roi2, loi))\n",
    "    ua = union.area\n",
    "    ia = inter.area\n",
    "    if ua == 0:\n",
    "        if ia == 0:\n",
    "            return 1\n",
    "        return 0\n",
    "    return ia/ua\n",
    "\n",
    "def iou(roi1, roi2):\n",
    "    union = unary_union([roi1, roi2]).area\n",
    "    inter = roi1.intersection(roi2).area\n",
    "    return inter/union\n",
    "\n",
    "def false_negatives(roi1, roi2):\n",
    "    fn = 0\n",
    "    tot = unary_union(roi2)\n",
    "    for man in roi1:\n",
    "        if not man.intersects(tot):\n",
    "            fn += 1\n",
    "    return fn\n",
    "\n",
    "def false_positives(roi1, roi2):\n",
    "    fp = 0\n",
    "    tot = unary_union(roi1)\n",
    "    for pred in roi2:\n",
    "        if not pred.intersects(tot):\n",
    "            fp += 1\n",
    "    return fp\n",
    "\n",
    "def true_positives_iou(roi1, roi2, loi, iou):\n",
    "    tp = 0\n",
    "    for (c1, c2) in loi:\n",
    "        if iou(c1, c2) >= iou:\n",
    "            tp += 1\n",
    "    return tp\n",
    "\n",
    "def relation_categorization_iou(l1, l2, loi, thresh):\n",
    "    part = 0\n",
    "    trans = 0\n",
    "    endo = 0\n",
    "    peri = 0\n",
    "    tp = 0\n",
    "    fp = false_positives(l1, l2)\n",
    "    fn = false_negatives(l1, l2)\n",
    "    for (c1, c2) in loi:\n",
    "        if iou(c1, c2) > thresh:\n",
    "            tp += 1\n",
    "        elif c1.crosses(c2):\n",
    "            trans += 1\n",
    "        elif c1.within(c2):\n",
    "            peri += 1\n",
    "        elif c1.covers(c2):\n",
    "            endo += 1\n",
    "        elif c1.overlaps(c2):\n",
    "            part += 1\n",
    "    cat = {'True Positives': tp, 'False Positives': fp, 'False Negatives': fn, 'Partial Errors': part, 'Inner Errors': endo, 'Excess Errors': peri, 'Crossing Errors': trans}\n",
    "    return cat\n",
    "    \n",
    "def recall(l1, l2, loi):\n",
    "    if len(l1) == 0:\n",
    "        if len(l2) != 0:\n",
    "            return 0\n",
    "        return None\n",
    "    tot = unary_union(l1).area\n",
    "    if tot == 0:\n",
    "        if len(l2) == 0:\n",
    "            return None\n",
    "        return 0\n",
    "    correct = unary_union(intersect(l1, l2, loi)).area\n",
    "    return correct/tot\n",
    "\n",
    "def precision(l1, l2, loi):\n",
    "    if len(l2) == 0:\n",
    "        if len(l1) != 0:\n",
    "            return 0\n",
    "        return None\n",
    "    tot = unary_union(l2).area\n",
    "    if tot == 0:\n",
    "        if len(l1) == 0:\n",
    "            return None\n",
    "        return 0\n",
    "    correct = unary_union(intersect(l1, l2, loi)).area\n",
    "    return correct/tot\n",
    "\n",
    "def f1_score(l1, l2, loi):\n",
    "    if len(l1) == 0:\n",
    "        if len(l2) != 0:\n",
    "            return 0\n",
    "        return None\n",
    "    prec = precision(l1, l2, loi)\n",
    "    rec = recall(l1, l2, loi)\n",
    "    if prec+rec == 0:\n",
    "        return 0\n",
    "    return 2*prec*rec/(prec+rec)\n",
    "\n",
    "def cell_prec(l1, l2, bound, liou):\n",
    "    count = 0\n",
    "    if len(l2) == 0:\n",
    "        return None\n",
    "    elif len(l1) == 0:\n",
    "        return 0\n",
    "    for i in liou:\n",
    "        if i >= bound:\n",
    "            count += 1\n",
    "    return count/len(l2)\n",
    "\n",
    "def cell_prec_50_95(l1, l2, liou):\n",
    "    b = 0.5\n",
    "    res = 0\n",
    "    if len(l2) == 0:\n",
    "        return None\n",
    "    elif len(l1) == 0:\n",
    "        return 0\n",
    "    for i in range(10):\n",
    "        res += cell_prec(l1, l2, b, liou)\n",
    "        b += 0.05\n",
    "    return res/10\n",
    "\n",
    "def cell_rec(l1, l2, bound, liou):\n",
    "    count = 0\n",
    "    if len(l1) == 0:\n",
    "        return None\n",
    "    elif len(l2) == 0:\n",
    "        return 0\n",
    "    for i in liou:\n",
    "        if i >= bound:\n",
    "            count += 1\n",
    "    return count/len(l1)\n",
    "\n",
    "def cell_rec_50_95(l1, l2, liou):\n",
    "    b = 0.5\n",
    "    res = 0\n",
    "    if len(l1) == 0:\n",
    "        return None\n",
    "    elif len(l2) == 0:\n",
    "        return 0\n",
    "    for i in range(10):\n",
    "        res += cell_rec(l1, l2, b, liou)\n",
    "        b += 0.05\n",
    "    return res/10\n",
    "\n",
    "def cell_f1(l1, l2, bound, liou):\n",
    "    if len(l1) == 0 and len(l2) == 0:\n",
    "        return None\n",
    "    elif len(l1) == 0 or len(l2) == 0:\n",
    "        return 0\n",
    "    prec = cell_prec(l1, l2, bound, liou)\n",
    "    rec = cell_rec(l1, l2, bound, liou)\n",
    "    if prec == None or rec == None:\n",
    "        return 0\n",
    "    elif prec+rec == 0:\n",
    "        return 0\n",
    "    return 2*prec*rec/(prec+rec)\n",
    "\n",
    "def cell_f1_50_95(l1, l2, liou):\n",
    "    b = 0.5\n",
    "    res = 0\n",
    "    if len(l1) == 0 and len(l2) == 0:\n",
    "        return None\n",
    "    elif len(l1) == 0 or len(l2) == 0:\n",
    "        return 0\n",
    "    for i in range(10):\n",
    "        res += cell_f1(l1, l2, b, liou)\n",
    "        b += 0.05\n",
    "    return res/10\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']\n",
    "\n",
    "def normalize_yolo(man_dir, pred_dir):\n",
    "    for filename in os.listdir(man_dir):\n",
    "        if filename not in os.listdir(pred_dir) and re.findall(r'\\d+', filename) not in [re.findall(r'\\d+', i) for i in os.listdir(pred_dir)]:\n",
    "            df = pd.DataFrame(columns=['Name', 'X', 'Y'])\n",
    "            df.to_csv(os.path.join(pred_dir, filename))\n",
    "\n",
    "def list_mapping(i_dir, j_dir):\n",
    "    aligned = []\n",
    "    for i in i_dir:\n",
    "        for j in j_dir:\n",
    "            if i.split('.')[0] == j.split('.')[0]:\n",
    "                aligned.append((i, j))\n",
    "            elif re.findall(r'\\d+', i) == re.findall(r'\\d+', j):\n",
    "                aligned.append((i, j))\n",
    "    print(aligned)\n",
    "    return aligned\n",
    "\n",
    "def avg_col(d):\n",
    "    sum_col = 0\n",
    "    count = 0\n",
    "    for i in d:\n",
    "        if i is not None:\n",
    "            sum_col += i\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return None\n",
    "    return sum_col/count\n",
    "\n",
    "def total_area(l1, l2):\n",
    "    return unary_union(l1 + l2).area\n",
    "\n",
    "def weighted_avg(values, weights, names):\n",
    "    total = 0\n",
    "    weight_sum = 0\n",
    "    for v, w, name in zip(values, weights, names):\n",
    "        if isinstance(v, (int, float)) and isinstance(w, (int, float)) and 'Statistics' not in name:\n",
    "            total += v * w\n",
    "            weight_sum += w\n",
    "    return total / weight_sum if weight_sum != 0 else None\n",
    "\n",
    "def object_avg(c, man, pred, n):\n",
    "    tot_man = 0\n",
    "    tot_pred = 0\n",
    "    res = 0\n",
    "    for i, j, m in zip(man, pred, n):\n",
    "        if 'Statistics' not in m:\n",
    "            tot_man += i\n",
    "            tot_pred += j\n",
    "    if tot_man+tot_pred == 0:\n",
    "        return None\n",
    "    for j, k, l, m in zip(c, man, pred, n):\n",
    "        if j is not None and 'Statistics' not in m:\n",
    "            if 'cell_prec' in m or 'Prec' in m:\n",
    "                ratio = l/tot_pred\n",
    "                res += j*ratio\n",
    "            elif 'cell_rec' in m or 'Rec' in m:\n",
    "                ratio = k/tot_man\n",
    "                res += j*ratio\n",
    "            else:\n",
    "                ratio = (k+l)/(tot_man+tot_pred)\n",
    "                res += j*ratio\n",
    "    print(f'Result:', res)\n",
    "    return res\n",
    "\n",
    "def compute_ap(loi, num_gt, iou_thresh=0.5):\n",
    "    matched_gt = set()\n",
    "    matched_pred = set()\n",
    "    tp = []\n",
    "    fp = []\n",
    "\n",
    "    # Compute IoU for all pairs in loi using your function\n",
    "    ious_with_pairs = [\n",
    "        (p1, p2, iou(p1, p2)) for (p1, p2) in loi\n",
    "    ]\n",
    "    ious_with_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    if len(ious_with_pairs) == 0:\n",
    "        return 0\n",
    "        \n",
    "    for p1, p2, iou_val in ious_with_pairs:\n",
    "        gt_id = id(p1)\n",
    "        pred_id = id(p2)\n",
    "\n",
    "        if iou_val >= iou_thresh and gt_id not in matched_gt and pred_id not in matched_pred:\n",
    "            tp.append(1)\n",
    "            fp.append(0)\n",
    "            matched_gt.add(gt_id)\n",
    "            matched_pred.add(pred_id)\n",
    "        else:\n",
    "            tp.append(0)\n",
    "            fp.append(1)\n",
    "\n",
    "    tp = np.cumsum(tp)\n",
    "    fp = np.cumsum(fp)\n",
    "\n",
    "    precisions = tp / (tp + fp + 1e-8)\n",
    "    recalls = tp / num_gt\n",
    "\n",
    "    precisions = np.concatenate([[1.0], precisions, [0.0]])\n",
    "    recalls = np.concatenate([[0.0], recalls, [1.0]])\n",
    "\n",
    "    for i in range(len(precisions) - 1, 0, -1):\n",
    "        precisions[i - 1] = max(precisions[i - 1], precisions[i])\n",
    "\n",
    "    ap = np.trapz(precisions, recalls)\n",
    "    return ap\n",
    "\n",
    "def compute_map(loi, num_gt, iou_thresh_start=0.5, iou_thresh_end=0.95, step=0.05):\n",
    "    ap_values = []\n",
    "    \n",
    "    # Iterate through IoU thresholds from 0.5 to 0.95 (with a step of 0.05)\n",
    "    for iou_thresh in np.arange(iou_thresh_start, iou_thresh_end + step, step):\n",
    "        ap = compute_ap(loi, num_gt, iou_thresh)\n",
    "        ap_values.append(ap)\n",
    "    \n",
    "    # Return the mean of the computed AP values for the IoU thresholds\n",
    "    mAP_50_95 = np.mean(ap_values)\n",
    "    return mAP_50_95\n",
    "\n",
    "def optimized_model_eval(man_dir, pred_dir, thresh=0.5):\n",
    "    performance = {\n",
    "        'Name': [],\n",
    "        'Total Area': [],\n",
    "        'Total Manual Masks': [], \n",
    "        'Valid Manual Masks': [],\n",
    "        'Total Predicted Masks': [], \n",
    "        'Valid Predicted Masks': [],\n",
    "        'List of Intersections': [],\n",
    "        'List of IoUs': [],\n",
    "        'AP50': [],\n",
    "        'mAP50-95': [],\n",
    "        'cell_prec50': [],\n",
    "        'cell_prec50-95': [],\n",
    "        'cell_rec50': [],\n",
    "        'cell_rec50-95': [],\n",
    "        'cell_f1_50': [],\n",
    "        'cell_f1_50-95': [],\n",
    "        'Total IoU': [],\n",
    "        'pix_prec': [],\n",
    "        'pix_rec': [],\n",
    "        'pix_f1': [],\n",
    "        'List of Relations': []\n",
    "    }\n",
    "    \n",
    "    man_files = [f for f in os.listdir(man_dir) if f.endswith('.csv')]\n",
    "    pred_files = [f for f in os.listdir(pred_dir) if f.endswith('.csv')]\n",
    "    print(man_files, pred_files)\n",
    "    \n",
    "    file_mapping = list_mapping(man_files, pred_files)\n",
    "    print(file_mapping)\n",
    "\n",
    "    sum_cats = {}\n",
    "    for filename1, filename2 in tqdm(file_mapping, desc=\"Processing files\"):\n",
    "        man_path = os.path.join(man_dir, filename1)\n",
    "        pred_path = os.path.join(pred_dir, filename2)\n",
    "        \n",
    "        if os.path.isfile(man_path) and os.path.isfile(pred_path):\n",
    "            performance['Name'].append(filename1.replace('.csv', ''))\n",
    "            \n",
    "            # Read CSV files\n",
    "            man_data = pd.read_csv(man_path, delimiter=',')\n",
    "            pred_data = pd.read_csv(pred_path, delimiter=',')\n",
    "            \n",
    "            # Process data\n",
    "            rois_man, orig_man = read_csv_to_polygons(man_data)\n",
    "            rois_pred, orig_pred = read_csv_to_polygons(pred_data)\n",
    "            loi = list_of_intersections(rois_man, rois_pred)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            tot_area = total_area(rois_man, rois_pred)\n",
    "            iou_list = [iou(c1, c2) for c1, c2 in loi]\n",
    "\n",
    "            # Assuming `relation_categorization_iou` returns a dictionary\n",
    "            categories = relation_categorization_iou(rois_man, rois_pred, loi, thresh)\n",
    "            \n",
    "            # Iterate through the dictionary and sum the values based on keys\n",
    "            for key, value in categories.items():\n",
    "                if key in sum_cats:\n",
    "                    sum_cats[key] += value\n",
    "                else:\n",
    "                    sum_cats[key] = value\n",
    "\n",
    "            performance['AP50'].append(compute_ap(loi, len(rois_man)))\n",
    "            performance['mAP50-95'].append(compute_map(loi, len(rois_man)))\n",
    "            performance['Total Area'].append(tot_area)\n",
    "            performance['Total Manual Masks'].append(orig_man)\n",
    "            performance['Total Predicted Masks'].append(orig_pred)\n",
    "            performance['Valid Manual Masks'].append(len(rois_man))\n",
    "            performance['Valid Predicted Masks'].append(len(rois_pred))\n",
    "            performance['List of Intersections'].append(loi)\n",
    "            performance['List of IoUs'].append(iou_list)\n",
    "            performance['Total IoU'].append(tot_iou(rois_man, rois_pred, loi))\n",
    "            performance['cell_prec50'].append(cell_prec(rois_man, rois_pred, thresh, iou_list))\n",
    "            performance['cell_prec50-95'].append(cell_prec_50_95(rois_man, rois_pred, iou_list))\n",
    "            performance['cell_rec50'].append(cell_rec(rois_man, rois_pred, thresh, iou_list))\n",
    "            performance['cell_rec50-95'].append(cell_rec_50_95(rois_man, rois_pred, iou_list))\n",
    "            performance['cell_f1_50'].append(cell_f1(rois_man, rois_pred, thresh, iou_list))\n",
    "            performance['cell_f1_50-95'].append(cell_f1_50_95(rois_man, rois_pred, iou_list))\n",
    "            performance['pix_prec'].append(precision(rois_man, rois_pred, loi))\n",
    "            performance['pix_rec'].append(recall(rois_man, rois_pred, loi))\n",
    "            performance['pix_f1'].append(f1_score(rois_man, rois_pred, loi))\n",
    "            performance['List of Relations'].append(categories)\n",
    "    print(performance['AP50'])\n",
    "    print(performance['mAP50-95'])\n",
    "    \n",
    "    # Add summary statistics\n",
    "    def add_summary_statistic(stat_func):\n",
    "        performance['Name'].append('Summary Statistics')\n",
    "        performance['Total Area'].append(None)\n",
    "        performance['Total Manual Masks'].append(None)  # Keep the original list intact\n",
    "        performance['Total Predicted Masks'].append(None)\n",
    "        performance['Valid Manual Masks'].append(None)  # Keep the original list intact\n",
    "        performance['Valid Predicted Masks'].append(None)\n",
    "        performance['List of Intersections'].append(None)\n",
    "        performance['List of IoUs'].append(None)\n",
    "        for key in performance:\n",
    "            if key not in ['Name', 'List of Intersections', 'List of IoUs', 'List of Relations', 'Total Manual Masks', 'Total Predicted Masks', 'Valid Manual Masks', 'Valid Predicted Masks', 'Total Area']:\n",
    "                performance[key].append(stat_func(performance[key]))  # Add summary statistic as a separate entry\n",
    "        performance['List of Relations'].append(None)\n",
    "    \n",
    "    add_summary_statistic(avg_col)\n",
    "    \n",
    "    # Add weighted statistics\n",
    "    def add_weighted_statistic(stat_func):\n",
    "        performance['Name'].append('Pixel Weight Statistics')\n",
    "        performance['Total Area'].append(None)\n",
    "        performance['Total Manual Masks'].append(None)  # Keep the original list intact\n",
    "        performance['Total Predicted Masks'].append(None)\n",
    "        performance['Valid Manual Masks'].append(None)  # Keep the original list intact\n",
    "        performance['Valid Predicted Masks'].append(None)\n",
    "        performance['List of Intersections'].append(None)\n",
    "        performance['List of IoUs'].append(None)\n",
    "        for key in performance:\n",
    "            if key not in ['Name', 'List of Intersections', 'List of IoUs', 'List of Relations', 'Total Manual Masks', 'Total Predicted Masks', 'Valid Manual Masks', 'Valid Predicted Masks', 'Total Area']:\n",
    "                performance[key].append(stat_func(performance[key], performance['Total Area'], performance['Name']))  # Add weighted statistic as a separate entry\n",
    "        performance['List of Relations'].append(None)\n",
    "    \n",
    "    add_weighted_statistic(weighted_avg)\n",
    "\n",
    "    # Add cell statistics\n",
    "    def add_cell_weight_statistic(stat_func, sum_cats):\n",
    "        performance['Name'].append('Cell Weight Statistics')\n",
    "        performance['Total Area'].append(None)\n",
    "        performance['Total Manual Masks'].append(None)  # Keep the original list intact\n",
    "        performance['Total Predicted Masks'].append(None)\n",
    "        performance['Valid Manual Masks'].append(None)  # Keep the original list intact\n",
    "        performance['Valid Predicted Masks'].append(None)\n",
    "        performance['List of Intersections'].append(None)\n",
    "        performance['List of IoUs'].append(None)\n",
    "        for key in performance:\n",
    "            if key not in ['Name', 'List of Intersections', 'List of IoUs', 'List of Relations', 'Total Manual Masks', 'Total Predicted Masks', 'Valid Manual Masks', 'Valid Predicted Masks', 'Total Area', 'cell_f1_50', 'cell_f1_50-95']:\n",
    "                performance[key].append(stat_func(performance[key], performance['Total Manual Masks'], performance['Total Predicted Masks'], performance['Name']))  # Add cell-weighted statistic as a separate entry\n",
    "        for key in ['cell_f1_50', 'cell_f1_50-95']:\n",
    "            prec = performance[key.replace('f1_', 'prec')][-1]\n",
    "            rec = performance[key.replace('f1_', 'rec')][-1]\n",
    "            if prec == None and rec == None:\n",
    "                f1 = None\n",
    "            elif prec == None or rec == None:\n",
    "                f1 =  0\n",
    "            elif prec+rec == 0:\n",
    "                f1 = 0\n",
    "            else:\n",
    "                f1 = 2*prec*rec/(prec+rec)\n",
    "            performance[key].append(f1)\n",
    "        performance['List of Relations'].append(sum_cats)\n",
    "    \n",
    "    add_cell_weight_statistic(object_avg, sum_cats)\n",
    "    \n",
    "    return performance\n",
    "\n",
    "\n",
    "#Evaluation for single-file\n",
    "def optimized_model_eval_files(man_path, pred_path, thresh=0.5):\n",
    "    performance = {\n",
    "        'Name': [],\n",
    "        'Total Area': [],\n",
    "        'Total Manual Masks': [], \n",
    "        'Valid Manual Masks': [],\n",
    "        'Total Predicted Masks': [], \n",
    "        'Valid Predicted Masks': [],\n",
    "        'List of Intersections': [],\n",
    "        'List of IoUs': [],\n",
    "        'AP50': [],\n",
    "        'mAP50-95': [],\n",
    "        'cell_prec50': [],\n",
    "        'cell_prec50-95': [],\n",
    "        'cell_rec50': [],\n",
    "        'cell_rec50-95': [],\n",
    "        'cell_f1_50': [],\n",
    "        'cell_f1_50-95': [],\n",
    "        'Total IoU': [],\n",
    "        'pix_prec': [],\n",
    "        'pix_rec': [],\n",
    "        'pix_f1': [],\n",
    "        'List of Relations': []\n",
    "    }\n",
    "    \n",
    "    performance['Name'].append(pred_path.replace('.csv', ''))\n",
    "            \n",
    "    # Read CSV files\n",
    "    man_data = pd.read_csv(man_path, delimiter=',')\n",
    "    print(man_data)\n",
    "    pred_data = pd.read_csv(pred_path, delimiter=',')\n",
    "            \n",
    "    # Process data\n",
    "    print('Manual conversion')\n",
    "    rois_man, orig_man = read_csv_to_polygons(man_data, False)\n",
    "    print(len(rois_man))\n",
    "    print(orig_man)\n",
    "    print('Prediction conversion')\n",
    "    rois_pred, orig_pred = read_csv_to_polygons(pred_data, False)\n",
    "    print(len(rois_pred))\n",
    "    print(orig_pred)\n",
    "    loi = list_of_intersections(rois_man, rois_pred)\n",
    "            \n",
    "    # Calculate metrics\n",
    "    tot_area = total_area(rois_man, rois_pred)\n",
    "    iou_list = [iou(c1, c2) for c1, c2 in loi]\n",
    "\n",
    "    performance['AP50'].append(compute_ap(loi, len(rois_man)))\n",
    "    performance['mAP50-95'].append(compute_map(loi, len(rois_man)))\n",
    "    performance['Total Area'].append(tot_area)\n",
    "    performance['Total Manual Masks'].append(orig_man)\n",
    "    performance['Total Predicted Masks'].append(orig_pred)\n",
    "    performance['Valid Manual Masks'].append(len(rois_man))\n",
    "    performance['Valid Predicted Masks'].append(len(rois_pred))\n",
    "    performance['List of Intersections'].append(loi)\n",
    "    performance['List of IoUs'].append(iou_list)\n",
    "    performance['Total IoU'].append(tot_iou(rois_man, rois_pred, loi))\n",
    "    performance['cell_prec50'].append(cell_prec(rois_man, rois_pred, thresh, iou_list))\n",
    "    performance['cell_prec50-95'].append(cell_prec_50_95(rois_man, rois_pred, iou_list))\n",
    "    performance['cell_rec50'].append(cell_rec(rois_man, rois_pred, thresh, iou_list))\n",
    "    performance['cell_rec50-95'].append(cell_rec_50_95(rois_man, rois_pred, iou_list))\n",
    "    performance['cell_f1_50'].append(cell_f1(rois_man, rois_pred, thresh, iou_list))\n",
    "    performance['cell_f1_50-95'].append(cell_f1_50_95(rois_man, rois_pred, iou_list))\n",
    "    performance['pix_prec'].append(precision(rois_man, rois_pred, loi))\n",
    "    performance['pix_rec'].append(recall(rois_man, rois_pred, loi))\n",
    "    performance['pix_f1'].append(f1_score(rois_man, rois_pred, loi))\n",
    "    performance['List of Relations'].append(relation_categorization_iou(rois_man, rois_pred, loi, thresh))\n",
    "    print(performance['cell_f1_50'])\n",
    "    print(performance['cell_f1_50-95'])\n",
    "    return performance\n",
    "\n",
    "def short_optimized_model_eval_files(man_path, pred_path, thresh = 0.5):\n",
    "    performance = {\n",
    "        'Name': [],\n",
    "        'Total Area': [],\n",
    "        'Total Manual Masks': [], \n",
    "        'Valid Manual Masks': [],\n",
    "        'Total Predicted Masks': [], \n",
    "        'Valid Predicted Masks': [],\n",
    "        'List of Intersections': [],\n",
    "        'List of IoUs': [],\n",
    "        'AP50': [],\n",
    "        'mAP50-95': [],\n",
    "        'cell_prec50': [],\n",
    "        'cell_prec50-95': [],\n",
    "        'cell_rec50': [],\n",
    "        'cell_rec50-95': [],\n",
    "        'cell_f1_50': [],\n",
    "        'cell_f1_50-95': [],\n",
    "        'Total IoU': [],\n",
    "        'pix_prec': [],\n",
    "        'pix_rec': [],\n",
    "        'pix_f1': []\n",
    "    }\n",
    "    \n",
    "    performance['Name'].append(pred_path.replace('.csv', ''))\n",
    "            \n",
    "    # Read CSV files\n",
    "    man_data = pd.read_csv(man_path, delimiter=',')\n",
    "    pred_data = pd.read_csv(pred_path, delimiter=',')\n",
    "            \n",
    "    # Process data\n",
    "    rois_man, orig_man = read_csv_to_polygons(man_data)\n",
    "    rois_pred, orig_pred = read_csv_to_polygons(pred_data)\n",
    "    loi = list_of_intersections(rois_man, rois_pred)\n",
    "            \n",
    "    # Calculate metrics\n",
    "    tot_area = total_area(rois_man, rois_pred)\n",
    "    iou_list = [iou(c1, c2) for c1, c2 in loi]\n",
    "\n",
    "    performance['AP50'].append(compute_ap(loi, len(rois_man)))\n",
    "    performance['mAP50-95'].append(compute_map(loi, len(rois_man)))\n",
    "    performance['Total Area'].append(tot_area)\n",
    "    performance['Total Manual Masks'].append(orig_man)\n",
    "    performance['Total Predicted Masks'].append(orig_pred)\n",
    "    performance['Valid Manual Masks'].append(len(rois_man))\n",
    "    performance['Valid Predicted Masks'].append(len(rois_pred))\n",
    "    performance['List of Intersections'].append(loi)\n",
    "    performance['List of IoUs'].append(iou_list)\n",
    "    performance['Total IoU'].append(tot_iou(rois_man, rois_pred, loi))\n",
    "    performance['cell_prec50'].append(cell_prec(rois_man, rois_pred, thresh, iou_list))\n",
    "    performance['cell_prec50-95'].append(cell_prec_50_95(rois_man, rois_pred, iou_list))\n",
    "    performance['cell_rec50'].append(cell_rec(rois_man, rois_pred, thresh, iou_list))\n",
    "    performance['cell_rec50-95'].append(cell_rec_50_95(rois_man, rois_pred, iou_list))\n",
    "    performance['cell_f1_50'].append(cell_f1(rois_man, rois_pred, thresh, iou_list))\n",
    "    performance['cell_f1_50-95'].append(cell_f1_50_95(rois_man, rois_pred, iou_list))\n",
    "    performance['pix_prec'].append(precision(rois_man, rois_pred, loi))\n",
    "    performance['pix_rec'].append(recall(rois_man, rois_pred, loi))\n",
    "    performance['pix_f1'].append(f1_score(rois_man, rois_pred, loi))\n",
    "    return performance\n",
    "\n",
    "#FOLDER BASED EVALUATION\n",
    "man_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123/UnremovedTranscriptsTxt/Test'\n",
    "pred_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Yolo/test_predictions/csv/'\n",
    "out_path = ''\n",
    "\n",
    "#normalize_yolo(man_dir, pred_dir)\n",
    "#performance = optimized_model_eval(man_dir, pred_dir)\n",
    "\n",
    "#df_csv = pd.DataFrame.from_dict(performance)\n",
    "#df_csv.to_csv(out_path)\n",
    "\n",
    "#FILE BASED EVALUATION\n",
    "#Input: path to manual annotations (csv), path to predicted annotations (csv), output path (csv)\n",
    "#Output: csv of relevant evaluation metrics (IoU, precision, recall, f1-score, etc.)\n",
    "man_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Xenium_segementation/ManuscriptProject/Scaled_DRG_Manual_Annotations/tg1_manual_scaled.csv'\n",
    "pred_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DRG123_Merged_New/DRG Merged Images/Eval/tg1.csv'\n",
    "out_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/DRG123_Merged_New/DRG Merged Images/Eval/tg1_eval.csv'\n",
    "\n",
    "#performance = optimized_model_eval_files(man_path, pred_path)\n",
    "\n",
    "#df_csv = pd.DataFrame.from_dict(performance)\n",
    "#df_csv.to_csv(out_path)\n",
    "print('Ready')F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaae71a-33c9-4631-a34f-57b489f07a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
