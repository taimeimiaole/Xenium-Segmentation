{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a368e9-1dfa-401d-b9ea-d6da4cb30e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from read_roi import read_roi_file, read_roi_zip\n",
    "from cellpose import core, utils, io, models, metrics, plot, train\n",
    "import time\n",
    "\n",
    "def extracting_rois(file_path, img_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.read().splitlines()\n",
    "    rois = []\n",
    "    img = Image.open(img_path)\n",
    "    width, height = img.size\n",
    "    for i in lines:\n",
    "        rois.append(list(map(float, i.split())))\n",
    "    rois_filtered = []\n",
    "    for i in rois:\n",
    "        rois_filtered.append(i[1:])\n",
    "    int_rois = []\n",
    "    for i in rois_filtered:\n",
    "        count = 0\n",
    "        x = []\n",
    "        y = []\n",
    "        for j in i:\n",
    "            if count%2:\n",
    "                x.append(int(round(j*width)))\n",
    "            else:\n",
    "                y.append(int(round(j*height)))\n",
    "            count += 1\n",
    "        temp = list(zip(x, y))\n",
    "        filt = []\n",
    "        for i in temp:\n",
    "            if i not in filt:\n",
    "                filt.append(i)\n",
    "        int_rois.append(filt)\n",
    "    return int_rois\n",
    "\n",
    "def save_rois_with_conversion(masks, files, output_dir):\n",
    "    # Ensure all masks are in the correct format\n",
    "    masks = [mask.astype(np.uint16) if mask.dtype != np.uint16 else mask for mask in masks]\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    count = 0\n",
    "    for file, mask in zip(files, masks):\n",
    "        count += 1\n",
    "        output_path = os.path.join(output_dir, file.split('/')[-1].replace('.jpg',''))\n",
    "        io.save_rois(mask, output_path)\n",
    "\n",
    "def zip_to_csv(directory):\n",
    "    for filename in [i for i in os.listdir(directory) if '.zip' in i]:\n",
    "        df_data = {'Name': [], 'X': [], 'Y': []}\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        data = read_roi_zip(file_path)\n",
    "        for name, roi in data.items():\n",
    "            df_data['X'].extend(roi['x'])\n",
    "            df_data['Y'].extend(roi['y'])\n",
    "            for i in range(len(roi['x'])):\n",
    "                df_data['Name'].append(str(roi['name']))\n",
    "        df = pd.DataFrame.from_dict(df_data)\n",
    "        out_dir = os.path.join(directory, 'csv')\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        df.to_csv(os.path.join(out_dir, filename).replace('.zip','.csv').replace('_rois','').replace('Nonseg','Seg'), sep=',', index=False, header=True)\n",
    "\n",
    "def csv_png(filename, height, width):\n",
    "    rois = pd.read_csv(filename)\n",
    "    image_height = height\n",
    "    image_width = width\n",
    "    grouped_rois = rois.groupby('Name')\n",
    "    count = 1\n",
    "    masks = []\n",
    "    for id, group in grouped_rois:\n",
    "        single_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "        polygon = [(x, y) for x, y in zip(group['X'], group['Y'])]\n",
    "        pts = np.array(polygon, dtype=np.int32)\n",
    "        pts = pts.reshape((-1, 1, 2))\n",
    "        cv2.fillPoly(single_mask, [pts], color=count)\n",
    "        masks.append(single_mask)\n",
    "        count += 1\n",
    "    if len(masks) == 0:\n",
    "        return np.zeros((width, height), dtype=np.uint16)\n",
    "    masks_array = np.stack(masks, axis=0)\n",
    "    combined = np.max(masks_array, axis = 0)\n",
    "    return combined\n",
    "\n",
    "def folder_mapping(i_dir, j_dir):\n",
    "    aligned = []\n",
    "    for i in os.listdir(i_dir):\n",
    "        for j in os.listdir(j_dir):\n",
    "            if i.split()[0] == j.split()[0]:\n",
    "                aligned.append((i, j))\n",
    "    return aligned\n",
    "\n",
    "def list_mapping(i_dir, j_dir):\n",
    "    aligned = []\n",
    "    for i in i_dir:\n",
    "        for j in j_dir:\n",
    "            if i.split('.')[0] == j.split('.')[0]:\n",
    "                aligned.append((i, j))\n",
    "            elif re.findall(r'\\d+', i) == re.findall(r'\\d+', j):\n",
    "                aligned.append((i, j))\n",
    "    print(aligned)\n",
    "    return aligned\n",
    "\n",
    "def check_unused_img(un_dir, u_dir, min_masks):\n",
    "    for maskname in [i for i in os.listdir(un_dir) if '_masks' in i]:\n",
    "        m_path = os.path.join(un_dir, maskname)\n",
    "        marr = np.array(Image.open(m_path))\n",
    "        num_masks = np.max(marr)\n",
    "        if num_masks >= min_masks:\n",
    "            os.rename(m_path, os.path.join(u_dir, maskname))\n",
    "            os.rename(m_path.replace('_masks.png', '.jpg'), os.path.join(u_dir, maskname.replace('_masks.png', '.jpg')))\n",
    "\n",
    "def check_unused_csv(un_dir, u_dir, min_masks):\n",
    "    for csvname in [i for i in os.listdir(un_dir) if '.csv' in i]:\n",
    "        c_path = os.path.join(un_dir, csvname)\n",
    "        csv = pd.read_csv(c_path)\n",
    "        if len(csv.groupby('Name')) >= min_masks:\n",
    "            os.rename(c_path, os.path.join(u_dir, csvname))\n",
    "            os.rename(c_path.replace('.csv', '.txt'), os.path.join(u_dir, csvname.replace('.csv', '.txt')))\n",
    "\n",
    "def add_unused_csv(un_dir, u_dir, min_masks):\n",
    "    for csvname in [i for i in os.listdir(u_dir) if '.csv' in i]:\n",
    "        c_path = os.path.join(u_dir, csvname)\n",
    "        csv = pd.read_csv(c_path)\n",
    "        if len(csv.groupby('Name')) < min_masks:\n",
    "            os.rename(c_path, os.path.join(un_dir, csvname))\n",
    "            os.rename(c_path.replace('.csv', '.txt'), os.path.join(un_dir, csvname.replace('.csv', '.txt')))\n",
    "\n",
    "def add_unused_img(un_dir, u_dir, min_masks):\n",
    "    for maskname in [i for i in os.listdir(u_dir) if '_masks' in i]:\n",
    "        m_path = os.path.join(u_dir, maskname)\n",
    "        marr = np.array(Image.open(m_path))\n",
    "        num_masks = np.max(marr)\n",
    "        if num_masks < min_masks:\n",
    "            os.rename(m_path, os.path.join(un_dir, maskname))\n",
    "            os.rename(m_path.replace('_masks.png', '.jpg'), os.path.join(un_dir, maskname.replace('_masks.png', '.jpg')))\n",
    "\n",
    "def manage_unused(ui_dir, i_dir, uf_dir, f_dir, min_masks):\n",
    "    add_unused_img(ui_dir, i_dir, min_masks)\n",
    "    add_unused_csv(uf_dir, f_dir, min_masks)\n",
    "    check_unused_img(ui_dir, i_dir, min_masks)\n",
    "    check_unused_csv(uf_dir, f_dir, min_masks)\n",
    "\n",
    "%run /media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Code/evaluationPipeline.ipynb\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "\n",
    "#Original Directory\n",
    "base_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Batch2/DRG123'\n",
    "\n",
    "initial_models = ['CPx', 'cyto2_cp3', 'cyto2', 'cyto3']\n",
    "\n",
    "img_folder = 'H&EStain'\n",
    "txt_folder = 'UnremovedTranscriptsTxt'\n",
    "min_masks = 5\n",
    "c1 = \"Red\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "c2 = \"Green\" #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "if img_folder == 'H&EStain' and 'Batch1' in base_dir and 'TG1' in base_dir:\n",
    "    model_name = \"heDRG123TG1_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'1_'+initial_model\n",
    "elif img_folder == 'UnremovedTranscripts' and 'Batch1' in base_dir and 'TG1' in base_dir:\n",
    "    model_name = \"transDRG123TG1_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'1_'+initial_model\n",
    "elif img_folder == 'H&EStain'  and 'TG1' in base_dir:\n",
    "    model_name = \"heDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'2_'+initial_model\n",
    "elif 'TG1' in base_dir:\n",
    "    model_name = \"transDRG123TG1_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'2_'+initial_model\n",
    "elif img_folder == 'H&EStain' and 'Batch1' in base_dir:\n",
    "    model_name = \"heDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'1_'+initial_model\n",
    "elif img_folder == 'UnremovedTranscripts' and 'Batch1' in base_dir:\n",
    "    model_name = \"transDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'1_'+initial_model\n",
    "elif img_folder == 'H&EStain':\n",
    "    model_name = \"heDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'2_'+initial_model\n",
    "else:\n",
    "    model_name = \"transDRG123_\"+str(min_masks)+\"masks_\"+c1[0]+c2[0]+'2_'+initial_model\n",
    "\n",
    "man_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/ManualDRG4/drg4manual.csv'\n",
    "#@markdown threshold on flow error to accept a mask (set higher to get more cells, e.g. in range from (0.1, 3.0), OR set to 0.0 to turn off so no cells discarded):\n",
    "flow_threshold = 0.4 #@param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
    "#@markdown threshold on cellprob output to seed cell masks (set lower to include more pixels or higher to include fewer, e.g. in range from (-6, 6)):\n",
    "cellprob_threshold = 0 #@param {type:\"slider\", min:-6, max:6, step:1}\n",
    "    \n",
    "out_path_drg4 = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Default Model Training Comparison HE/'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'drg4.csv'\n",
    "out_path_test = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Default Model Training Comparison HE/'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'test.csv'\n",
    "heat_map_out_path = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Default Prob Maps/he_trained_'+model_name+'_'+str(flow_threshold)+'_'+str(cellprob_threshold)+'drg4.svg'\n",
    "    \n",
    "for i in initial_models:\n",
    "    initial_model = i\n",
    "    model_name = model_name+initial_model\n",
    "    \n",
    "    train_dir = os.path.join(base_dir, img_folder, 'Train')\n",
    "    test_dir = os.path.join(base_dir, img_folder, 'Test')\n",
    "    \n",
    "    man_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/ManualDRG4'\n",
    "    if img_folder == 'H&EStain':\n",
    "        eval_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/DRG4HeImg'\n",
    "        pred_path = eval_dir + '/csv/drg4.csv'\n",
    "    else:\n",
    "        eval_dir = '/media/yhs/5596744f-db7c-442f-9235-d0c9d50c0a6b/Cellpose/Updated_Figures/Evaluation Image/TransDRG4'\n",
    "        pred_path = eval_dir + '/csv/croppedDRG4.csv'\n",
    "    \n",
    "    #RUN THIS CELL TO INITIALIZE ALL REQUIRED FILES\n",
    "    \n",
    "    directory = os.path.join(base_dir, txt_folder)\n",
    "    folders = [os.path.join(directory, entry) for entry in os.listdir(directory) if os.path.isdir(os.path.join(directory, entry))]\n",
    "    \n",
    "    for folder in folders:\n",
    "        f_dir = os.path.join(directory, folder)\n",
    "        i_dir = f_dir.replace(txt_folder, img_folder)\n",
    "        ui_dir = os.path.join(i_dir, 'unused')\n",
    "        uf_dir = os.path.join(f_dir, 'unused')\n",
    "        os.makedirs(ui_dir, exist_ok=True)\n",
    "        os.makedirs(uf_dir, exist_ok=True)\n",
    "        for filename, imgname in list_mapping([i for i in os.listdir(f_dir) if '.txt' in i], [j for j in os.listdir(i_dir) if '.jpg' in j]):\n",
    "            file_path = os.path.join(f_dir, filename)\n",
    "            img_path = os.path.join(i_dir, imgname)\n",
    "            data = extracting_rois(file_path, img_path)\n",
    "            df = {'Name': [], 'X': [], 'Y': []}\n",
    "            count = 1\n",
    "            for i in data:\n",
    "                df['Name'].extend(['roi'+str(count) for j in i])\n",
    "                df['X'].extend([k for j, k in i])\n",
    "                df['Y'].extend([j for j, k in i])\n",
    "                count += 1\n",
    "            df_csv = pd.DataFrame(df)\n",
    "            df_csv.to_csv(os.path.join(f_dir, filename.replace('.txt','.csv')))\n",
    "        for filename, imgname in list_mapping([i for i in os.listdir(f_dir) if '.csv' in i], [j for j in os.listdir(i_dir) if '.jpg' in j]):\n",
    "            file_path = os.path.join(f_dir, filename)\n",
    "            img_path = os.path.join(i_dir, imgname)\n",
    "            imarr = csv_png(file_path, 500, 500)\n",
    "            im = Image.fromarray(imarr)\n",
    "            im.save(os.path.join(img_path.replace('.jpg','_masks.png')))\n",
    "    \n",
    "    #FILTERS NEW CELLS\n",
    "    for folder in folders:\n",
    "        f_dir = os.path.join(directory, folder)\n",
    "        i_dir = f_dir.replace(txt_folder, img_folder)\n",
    "        ui_dir = os.path.join(i_dir, 'unused')\n",
    "        uf_dir = os.path.join(f_dir, 'unused')\n",
    "        manage_unused(ui_dir, i_dir, uf_dir, f_dir, min_masks)\n",
    "    \n",
    "    # other parameters for training.\n",
    "    #@markdown ###Training Parameters:\n",
    "    #@markdown Number of epochs:\n",
    "    n_epochs =  100#@param {type:\"number\"}\n",
    "    \n",
    "    Channel_to_use_for_training = c1 #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "    Second_training_channel= c2 #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    #@markdown ###Advanced Parameters\n",
    "    \n",
    "    Use_Default_Advanced_Parameters = True #@param {type:\"boolean\"}\n",
    "    #@markdown ###If not, please input:\n",
    "    learning_rate = 0.1 #@param {type:\"number\"}\n",
    "    weight_decay = 0.0001 #@param {type:\"number\"}\n",
    "    \n",
    "    if (Use_Default_Advanced_Parameters):\n",
    "      print(\"Default advanced parameters enabled\")\n",
    "      learning_rate = 0.1\n",
    "      weight_decay = 0.0001\n",
    "    \n",
    "    #here we check that no model with the same name already exist, if so delete\n",
    "    model_path = train_dir + '/models'\n",
    "    if os.path.exists(model_path+'/'+model_name):\n",
    "      print(\"!! WARNING: \"+model_name+\" already exists and will be deleted in the following cell !!\")\n",
    "    \n",
    "    if len(test_dir) == 0:\n",
    "      test_dir = None\n",
    "    \n",
    "    # Here we match the channel to number\n",
    "    if Channel_to_use_for_training == \"Grayscale\":\n",
    "      chan = 0\n",
    "    elif Channel_to_use_for_training == \"Blue\":\n",
    "      chan = 3\n",
    "    elif Channel_to_use_for_training == \"Green\":\n",
    "      chan = 2\n",
    "    elif Channel_to_use_for_training == \"Red\":\n",
    "      chan = 1\n",
    "    \n",
    "    \n",
    "    if Second_training_channel == \"Blue\":\n",
    "      chan2 = 3\n",
    "    elif Second_training_channel == \"Green\":\n",
    "      chan2 = 2\n",
    "    elif Second_training_channel == \"Red\":\n",
    "      chan2 = 1\n",
    "    elif Second_training_channel == \"None\":\n",
    "      chan2 = 0\n",
    "    \n",
    "    if initial_model=='scratch':\n",
    "      initial_model = 'None'\n",
    "        \n",
    "    \n",
    "    # start logger (to see training across epochs)\n",
    "    logger = io.logger_setup()\n",
    "    \n",
    "    # DEFINE CELLPOSE MODEL (without size model)\n",
    "    model = models.CellposeModel(gpu=use_GPU, model_type=initial_model)\n",
    "    \n",
    "    # set channels\n",
    "    channels = [chan, chan2]\n",
    "    \n",
    "    # get files\n",
    "    output = io.load_train_test_data(train_dir, test_dir, mask_filter='_masks')\n",
    "    train_data, train_labels, _, test_data, test_labels, _ = output\n",
    "    \n",
    "    nimg = len(train_data)\n",
    "    \n",
    "    new_model_path = train.train_seg(model.net, train_data=train_data,\n",
    "                                  train_labels=train_labels,\n",
    "                                  test_data=test_data,\n",
    "                                  test_labels=test_labels,\n",
    "                                  channels=channels,\n",
    "                                  save_path=train_dir,\n",
    "                                  n_epochs=n_epochs,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  weight_decay=weight_decay,\n",
    "                                  SGD=True,                            \n",
    "                                  nimg_per_epoch=8,\n",
    "                                  min_train_masks=min_masks,\n",
    "                                  model_name=model_name)\n",
    "    \n",
    "    # diameter of labels in training images\n",
    "    diam_labels = model.net.diam_labels.item()\n",
    "    \n",
    "    # get files (during training, test_data is transformed so we will load it again)\n",
    "    output = io.load_train_test_data(test_dir, mask_filter='_masks')\n",
    "    test_data, test_labels = output[:2]\n",
    "        \n",
    "    # run model on test images\n",
    "    masks = model.eval(test_data,\n",
    "                       channels=[chan, chan2],\n",
    "                       diameter=diam_labels)[0]\n",
    "    \n",
    "    # check performance using ground truth labels\n",
    "    ap = metrics.average_precision(test_labels, masks)[0]\n",
    "    print('')\n",
    "    print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n",
    "    \n",
    "    print(diam_labels)\n",
    "    \n",
    "    # model name and path\n",
    "    \n",
    "    #@markdown ###Custom model path (full path):\n",
    "    \n",
    "    model_path = os.path.join(train_dir, 'models', model_name)\n",
    "    \n",
    "    #@markdown ###Path to images:\n",
    "    \n",
    "    dir = eval_dir #@param {type:\"string\"}\n",
    "    \n",
    "    #@markdown ###Channel Parameters:\n",
    "    \n",
    "    Channel_to_use_for_segmentation = c1 #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    # @markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
    "    \n",
    "    Second_segmentation_channel= c2 #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    \n",
    "    # Here we match the channel to number\n",
    "    if Channel_to_use_for_segmentation == \"Grayscale\":\n",
    "      chan = 0\n",
    "    elif Channel_to_use_for_segmentation == \"Blue\":\n",
    "      chan = 3\n",
    "    elif Channel_to_use_for_segmentation == \"Green\":\n",
    "      chan = 2\n",
    "    elif Channel_to_use_for_segmentation == \"Red\":\n",
    "      chan = 1\n",
    "    \n",
    "    \n",
    "    if Second_segmentation_channel == \"Blue\":\n",
    "      chan2 = 3\n",
    "    elif Second_segmentation_channel == \"Green\":\n",
    "      chan2 = 2\n",
    "    elif Second_segmentation_channel == \"Red\":\n",
    "      chan2 = 1\n",
    "    elif Second_segmentation_channel == \"None\":\n",
    "      chan2 = 0\n",
    "    \n",
    "    #@markdown ### Segmentation parameters:\n",
    "    \n",
    "    #@markdown diameter of cells (set to zero to use diameter from training set):\n",
    "    diameter =  diam_labels #@param {type:\"number\"}\n",
    "    \n",
    "    \n",
    "    # gets image files in dir (ignoring image files ending in _masks)\n",
    "    files = io.get_image_files(dir, '_masks')\n",
    "    images = [io.imread(f) for f in files]\n",
    "    \n",
    "    # declare model\n",
    "    model = models.CellposeModel(gpu=True,\n",
    "                                 pretrained_model=model_path)\n",
    "    \n",
    "    # use model diameter if user diameter is 0\n",
    "    diameter = model.diam_labels if diameter==0 else diameter\n",
    "    \n",
    "    # run model on test images\n",
    "    masks, flows, styles = model.eval(images,\n",
    "                                      channels=[chan, chan2],\n",
    "                                      diameter=diameter,\n",
    "                                      flow_threshold=flow_threshold,\n",
    "                                      cellprob_threshold=cellprob_threshold\n",
    "                                      )\n",
    "    \n",
    "    io.masks_flows_to_seg(images,\n",
    "                          masks,\n",
    "                          flows,\n",
    "                          files,\n",
    "                          channels=[chan, chan2],\n",
    "                          diams=diameter*np.ones(len(masks)),\n",
    "                          )\n",
    "    \n",
    "    save_rois_with_conversion(masks, files, eval_dir)\n",
    "    \n",
    "    zip_to_csv(eval_dir)\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(man_dir, 'csv')):\n",
    "        zip_to_csv(man_dir)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'DRG4 Eval Complete in {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    if img_folder == 'H&EStain':\n",
    "        performance = optimized_model_eval_files(man_path, pred_path)\n",
    "    else:\n",
    "        performance = optimized_model_eval_files(man_path, pred_path)\n",
    "    \n",
    "    df_csv = pd.DataFrame.from_dict(performance)\n",
    "    df_csv.to_csv(out_path_drg4)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time-start_time\n",
    "    \n",
    "    plt.figure(figsize=(8, 10))\n",
    "    plt.imshow(flows[0][2], cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label='Intensity')\n",
    "    plt.title('Heatmap Visualization')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.show()\n",
    "    plt.savefig(heat_map_out_path)\n",
    "    \n",
    "    print(f'Eval Pipeline Complete in {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    # model name and path\n",
    "    #duplicate the test folder and label it manual\n",
    "    \n",
    "    man_dir_1 = os.path.join(base_dir, txt_folder, 'Test')\n",
    "    eval_dir_1 = test_dir.replace('Test', 'Eval')\n",
    "    if os.path.isdir(eval_dir_1):\n",
    "        shutil.rmtree(eval_dir_1)\n",
    "    shutil.copytree(test_dir, eval_dir_1)\n",
    "    \n",
    "    print(txt_folder)\n",
    "    \n",
    "    eu_dir = os.path.join(eval_dir_1, 'unused')\n",
    "    tt_dir = os.path.join(base_dir, txt_folder, 'Test')\n",
    "    utt_dir = os.path.join(tt_dir, 'unused')\n",
    "    manage_unused(eu_dir, eval_dir_1, utt_dir, tt_dir, 0)\n",
    "    \n",
    "    #@markdown ###Custom model path (full path):\n",
    "    \n",
    "    model_path = os.path.join(train_dir, 'models', model_name)\n",
    "    \n",
    "    #@markdown ###Path to images:\n",
    "    \n",
    "    dir = eval_dir_1 #@param {type:\"string\"}\n",
    "    \n",
    "    #@markdown ###Channel Parameters:\n",
    "    \n",
    "    Channel_to_use_for_segmentation = c1 #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    # @markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
    "    \n",
    "    Second_segmentation_channel= c2 #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "    \n",
    "    \n",
    "    # Here we match the channel to number\n",
    "    if Channel_to_use_for_segmentation == \"Grayscale\":\n",
    "      chan = 0\n",
    "    elif Channel_to_use_for_segmentation == \"Blue\":\n",
    "      chan = 3\n",
    "    elif Channel_to_use_for_segmentation == \"Green\":\n",
    "      chan = 2\n",
    "    elif Channel_to_use_for_segmentation == \"Red\":\n",
    "      chan = 1\n",
    "    \n",
    "    \n",
    "    if Second_segmentation_channel == \"Blue\":\n",
    "      chan2 = 3\n",
    "    elif Second_segmentation_channel == \"Green\":\n",
    "      chan2 = 2\n",
    "    elif Second_segmentation_channel == \"Red\":\n",
    "      chan2 = 1\n",
    "    elif Second_segmentation_channel == \"None\":\n",
    "      chan2 = 0\n",
    "    \n",
    "    #@markdown ### Segmentation parameters:\n",
    "    \n",
    "    #@markdown diameter of cells (set to zero to use diameter from training set):\n",
    "    diameter =  diam_labels #@param {type:\"number\"}\n",
    "    \n",
    "    \n",
    "    # gets image files in dir (ignoring image files ending in _masks)\n",
    "    files = io.get_image_files(dir, '_masks')\n",
    "    images = [io.imread(f) for f in files]\n",
    "    \n",
    "    # declare model\n",
    "    model = models.CellposeModel(gpu=True,\n",
    "                                 pretrained_model=model_path)\n",
    "    \n",
    "    # use model diameter if user diameter is 0\n",
    "    diameter = model.diam_labels if diameter==0 else diameter\n",
    "    \n",
    "    # run model on test images\n",
    "    masks, flows, styles = model.eval(images,\n",
    "                                      channels=[chan, chan2],\n",
    "                                      diameter=diameter,\n",
    "                                      flow_threshold=flow_threshold,\n",
    "                                      cellprob_threshold=cellprob_threshold\n",
    "                                      )\n",
    "    \n",
    "    io.masks_flows_to_seg(images,\n",
    "                          masks,\n",
    "                          flows,\n",
    "                          files,\n",
    "                          channels=[chan, chan2],\n",
    "                          diams=diameter*np.ones(len(masks)),\n",
    "                          )\n",
    "    \n",
    "    save_rois_with_conversion(masks, files, eval_dir_1)\n",
    "    \n",
    "    zip_to_csv(eval_dir_1)\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(man_dir_1, 'csv')):\n",
    "        zip_to_csv(man_dir_1)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Test Folder Eval Complete in {elapsed_time:.2f} seconds')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    performance_1 = optimized_model_eval(man_dir_1, os.path.join(eval_dir_1, 'csv'))\n",
    "    \n",
    "    df_csv = pd.DataFrame.from_dict(performance_1)\n",
    "    df_csv.to_csv(out_path_test)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time-start_time\n",
    "    \n",
    "    print(f'Eval Pipeline Complete in {elapsed_time:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
