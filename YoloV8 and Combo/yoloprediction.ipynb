{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774d3d53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (8.2.52)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (1.24.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (4.10.0.82)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (2.4.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (0.19.1+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b05786a2-d7f4-4db1-80fb-cac82fd2638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed to: 42\n"
     ]
    }
   ],
   "source": [
    "#set seed\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Setting seed to: {seed}\")\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01dec5af-fa77-40ea-8d1c-b55d811d3674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify trained model\n",
    "trained_model=r\"path to trained model\" #can use last or best .pt\n",
    "model=YOLO(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a95ee-296f-4aa2-97b0-457531da24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For large images that must be cropped for prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6922549b-4fd1-4201-9e5f-c4cb7952d2c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2400, 5797] must be multiple of max stride 32, updating to [2400, 5824]\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict397\\crop_1\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\DRG1\\crop_1.tiff: 2400x1024 241 neurons, 33878.2ms\n",
      "Speed: 20.9ms preprocess, 33878.2ms inference, 687.1ms postprocess per image at shape (1, 3, 2400, 1024)\n",
      "Results saved to \u001b[1mruns\\segment\\predict397\u001b[0m\n",
      "1 label saved to runs\\segment\\predict397\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"path to image1\", imgsz=[x1,y1], max_det=400, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92015b0f-7d00-46fd-ab71-febe87e14e79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[5061, 5797] must be multiple of max stride 32, updating to [5088, 5824]\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict397\\crop_2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\DRG1\\crop_2.tiff: 5088x4448 229 neurons, 173655.8ms\n",
      "Speed: 193.9ms preprocess, 173655.8ms inference, 488.8ms postprocess per image at shape (1, 3, 5088, 4448)\n",
      "Results saved to \u001b[1mruns\\segment\\predict397\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict397\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"path to image2\", imgsz=[x2, y2], max_det=400, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7905cf0-9892-470b-842f-8b71d84a80e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4847, 2195] must be multiple of max stride 32, updating to [4864, 2208]\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict390\\Aligned_DRG2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG2\\Aligned_DRG2.tif: 1024x2208 323 neurons, 33896.4ms\n",
      "Speed: 28.0ms preprocess, 33896.4ms inference, 8704.2ms postprocess per image at shape (1, 3, 1024, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict390\u001b[0m\n",
      "3 labels saved to runs\\segment\\predict390\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"path to image3\", imgsz=[x3, y3], max_det=400, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4415a81c-e64e-48de-b103-14c6a3da0ce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[3045, 4356] must be multiple of max stride 32, updating to [3072, 4384]\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict401\\output-XETG00171__0018220__Region_3__20240207__003742\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 E:\\Xenium figures and manuscript\\Code and pipelines\\export\\transcripts\\output-XETG00171__0018220__Region_3__20240207__003742.tif: 3072x2176 284 neurons, 47530.4ms\n",
      "Speed: 55.4ms preprocess, 47530.4ms inference, 2689.2ms postprocess per image at shape (1, 3, 3072, 2176)\n",
      "Results saved to \u001b[1mruns\\segment\\predict401\u001b[0m\n",
      "1 label saved to runs\\segment\\predict401\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"path to image4\", imgsz=[x4, y4], max_det=400, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f00fac87-b3a7-4998-a319-204051035f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2200, 6300] must be multiple of max stride 32, updating to [2208, 6304]\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict393\\crop_1\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop2crops\\crop_1.tiff: 2208x800 310 neurons, 29168.9ms\n",
      "Speed: 15.5ms preprocess, 29168.9ms inference, 541.2ms postprocess per image at shape (1, 3, 2208, 800)\n",
      "Results saved to \u001b[1mruns\\segment\\predict393\u001b[0m\n",
      "1 label saved to runs\\segment\\predict393\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop2crops\\crop_1.tiff\", imgsz=[2200, 6300], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5623a60c-0b8a-4d98-95ab-6e8b26b95343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2773, 6300] must be multiple of max stride 32, updating to [2784, 6304]\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict393\\crop_2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop2crops\\crop_2.tiff: 2784x1248 150 neurons, 35859.7ms\n",
      "Speed: 42.8ms preprocess, 35859.7ms inference, 459.9ms postprocess per image at shape (1, 3, 2784, 1248)\n",
      "Results saved to \u001b[1mruns\\segment\\predict393\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict393\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop2crops\\crop_2.tiff\", imgsz=[2773, 6300], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6689b56-9849-4348-90ea-3fa08a1d1028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 2200] must be multiple of max stride 32, updating to [4512, 2208]\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_3\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_3.tiff: 1088x2208 475 neurons, 28406.0ms\n",
      "Speed: 27.9ms preprocess, 28406.0ms inference, 1663.7ms postprocess per image at shape (1, 3, 1088, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict392\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict392\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_3.tiff\", imgsz=[4500, 2200], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f150145-8be7-46f5-b979-8e0531b078cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 2000] must be multiple of max stride 32, updating to [4800, 2016]\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_4\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_4.tiff: 864x2016 272 neurons, 25362.2ms\n",
      "Speed: 24.0ms preprocess, 25362.2ms inference, 122.0ms postprocess per image at shape (1, 3, 864, 2016)\n",
      "Results saved to \u001b[1mruns\\segment\\predict392\u001b[0m\n",
      "3 labels saved to runs\\segment\\predict392\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_4.tiff\", imgsz=[4773, 2000], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c02bc6a-b4e0-4dd5-a9ba-af70b62ee374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 2180] must be multiple of max stride 32, updating to [4512, 2208]\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_5\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_5.tiff: 1088x2208 416 neurons, 28032.2ms\n",
      "Speed: 53.0ms preprocess, 28032.2ms inference, 753.4ms postprocess per image at shape (1, 3, 1088, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict392\u001b[0m\n",
      "4 labels saved to runs\\segment\\predict392\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_5.tiff\", imgsz=[4500, 2180], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1847e4b1-1b2b-492b-b903-8a2964757b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 2180] must be multiple of max stride 32, updating to [4800, 2208]\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_6\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_6.tiff: 1024x2208 39 neurons, 29154.4ms\n",
      "Speed: 27.4ms preprocess, 29154.4ms inference, 75.8ms postprocess per image at shape (1, 3, 1024, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict392\u001b[0m\n",
      "5 labels saved to runs\\segment\\predict392\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_6.tiff\", imgsz=[4773, 2180], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9488f61f-7bef-4077-ba31-b82809712ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 3936] must be multiple of max stride 32, updating to [4512, 3936]\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_7\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_7.tiff: 3456x3936 615 neurons, 59415.8ms\n",
      "Speed: 348.0ms preprocess, 59415.8ms inference, 20702.2ms postprocess per image at shape (1, 3, 3456, 3936)\n",
      "Results saved to \u001b[1mruns\\segment\\predict392\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict392\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_7.tiff\", imgsz=[4500, 3936], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "161f8ceb-3def-4010-9a61-a30f80b563a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 3936] must be multiple of max stride 32, updating to [4800, 3936]\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict392\\crop_8\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_8.tiff: 3264x3936 (no detections), 58950.6ms\n",
      "Speed: 800.3ms preprocess, 58950.6ms inference, 0.0ms postprocess per image at shape (1, 3, 3264, 3936)\n",
      "Results saved to \u001b[1mruns\\segment\\predict392\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict392\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\final_runs\\Merged\\TG1\\crop_8.tiff\", imgsz=[4773, 3936], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9c46dfc-77f5-4dc2-b864-9c84cb2be8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 2180] must be multiple of max stride 32, updating to [4800, 2208]\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict372\\crop_6\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\crop_6.tiff: 1024x2208 51 neurons, 53466.7ms\n",
      "Speed: 29.0ms preprocess, 53466.7ms inference, 5.0ms postprocess per image at shape (1, 3, 1024, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict372\u001b[0m\n",
      "5 labels saved to runs\\segment\\predict372\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\crop_6.tiff\", imgsz=[4773, 2180], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e21b36d8-a566-4efb-8644-94d97624a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 3936] must be multiple of max stride 32, updating to [4512, 3936]\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict372\\crop_7\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\crop_7.tiff: 3456x3936 637 neurons, 127219.0ms\n",
      "Speed: 2712.9ms preprocess, 127219.0ms inference, 30185.5ms postprocess per image at shape (1, 3, 3456, 3936)\n",
      "Results saved to \u001b[1mruns\\segment\\predict372\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict372\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\crop_7.tiff\", imgsz=[4500, 3936], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe98bac5-2608-4a31-a8d8-dccf57559441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 3936] must be multiple of max stride 32, updating to [4800, 3936]\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict372\\crop_8\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\crop_8.tiff: 3264x3936 (no detections), 53199.7ms\n",
      "Speed: 138.8ms preprocess, 53199.7ms inference, 0.0ms postprocess per image at shape (1, 3, 3264, 3936)\n",
      "Results saved to \u001b[1mruns\\segment\\predict372\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict372\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\crop_8.tiff\", imgsz=[4773, 3936], max_det=800, conf=0.25, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09b2e37-5216-47fb-90f7-5f1a42236e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[3045, 4356] must be multiple of max stride 32, updating to [3072, 4384]\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict293\\DRG3\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\ST_full\\DRG3.tif: 3072x2176 271 neurons, 53866.9ms\n",
      "Speed: 276.2ms preprocess, 53866.9ms inference, 46.4ms postprocess per image at shape (1, 3, 3072, 2176)\n",
      "Results saved to \u001b[1mruns\\segment\\predict293\u001b[0m\n",
      "4 labels saved to runs\\segment\\predict293\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\ST_full\\DRG3.tif\", imgsz=[3045, 4356], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1162c39f-4bbc-48b1-8ffe-d568811e9267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[3648, 5800] must be multiple of max stride 32, updating to [3648, 5824]\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict293\\DRG4\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\ST_full\\DRG4.tif: 3648x2304 297 neurons, 53856.0ms\n",
      "Speed: 91.8ms preprocess, 53856.0ms inference, 1439.8ms postprocess per image at shape (1, 3, 3648, 2304)\n",
      "Results saved to \u001b[1mruns\\segment\\predict293\u001b[0m\n",
      "5 labels saved to runs\\segment\\predict293\\labels\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "156e6e6b-0c42-446d-b78c-5eacb35fc0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2124, 5797] must be multiple of max stride 32, updating to [2144, 5824]\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict296\\crop_1\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_1.tiff: 2144x800 162 neurons, 29815.2ms\n",
      "Speed: 16.0ms preprocess, 29815.2ms inference, 7.0ms postprocess per image at shape (1, 3, 2144, 800)\n",
      "Results saved to \u001b[1mruns\\segment\\predict296\u001b[0m\n",
      "1 label saved to runs\\segment\\predict296\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_1.tiff\", imgsz=[2124, 5797], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa7057b-1f08-4cb6-a13b-c892dfd6a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[5361, 5797] must be multiple of max stride 32, updating to [5376, 5824]\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict298\\crop_2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_2.tiff: 5376x4992 278 neurons, 89646.3ms\n",
      "Speed: 196.4ms preprocess, 89646.3ms inference, 6464.9ms postprocess per image at shape (1, 3, 5376, 4992)\n",
      "Results saved to \u001b[1mruns\\segment\\predict298\u001b[0m\n",
      "1 label saved to runs\\segment\\predict298\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_2.tiff\", imgsz=[5361, 5797], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65de6a9b-6035-45a4-b05c-6257a46a3b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4847, 2195] must be multiple of max stride 32, updating to [4864, 2208]\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict298\\Aligned_DRG2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG2\\Aligned_DRG2.tif: 1024x2208 295 neurons, 27535.1ms\n",
      "Speed: 33.1ms preprocess, 27535.1ms inference, 1205.8ms postprocess per image at shape (1, 3, 1024, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict298\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict298\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG2\\Aligned_DRG2.tif\", imgsz=[4847, 2195], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f21a8-aa44-4a41-91a3-0c30023c9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG3\\Aligned_DRG3.tif\", imgsz=[3045, 4356], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cdf027-6506-4241-982d-d71499dd19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG4\\test_DRG4.tif\", imgsz=[3648, 5800], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f53b806f-7719-4c64-aad8-3856f6512021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 2180] must be multiple of max stride 32, updating to [4512, 2208]\n",
      "Saving runs\\segment\\predict295\\crop_5\\stage0_Conv_features.png... (32/32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMouse\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDownloads\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mHE_full\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTG1\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcrop_5.tiff\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2180\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_boxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_txt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\engine\\model.py:442\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\engine\\predictor.py:254\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 254\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:456\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 456\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\nn\\tasks.py:102\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\nn\\tasks.py:120\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\nn\\tasks.py:144\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    142\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n\u001b[1;32m--> 144\u001b[0m     \u001b[43mfeature_visualization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embed \u001b[38;5;129;01mand\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m embed:\n\u001b[0;32m    146\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(x, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# flatten\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\utils\\plotting.py:1291\u001b[0m, in \u001b[0;36mfeature_visualization\u001b[1;34m(x, module_type, stage, n, save_dir)\u001b[0m\n\u001b[0;32m   1289\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(f, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, bbox_inches\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1290\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1291\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;28mstr\u001b[39m(f\u001b[38;5;241m.\u001b[39mwith_suffix(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)), \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\HE_full\\TG1\\crop_5.tiff\", imgsz=[4500, 2180], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bdda145-8962-47d2-ba2f-fee332250fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 2180] must be multiple of max stride 32, updating to [4800, 2208]\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict280\\crop_6\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\HE_full\\TG1\\crop_6.tiff: 1024x2208 21 neurons, 31706.4ms\n",
      "Speed: 20.9ms preprocess, 31706.4ms inference, 3.6ms postprocess per image at shape (1, 3, 1024, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict280\u001b[0m\n",
      "5 labels saved to runs\\segment\\predict280\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\HE_full\\TG1\\crop_6.tiff\", imgsz=[4773, 2180], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1fbfa21-eb48-4a7e-96c7-e9c9ba8ca69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 3936] must be multiple of max stride 32, updating to [4512, 3936]\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict280\\crop_7\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\HE_full\\TG1\\crop_7.tiff: 3456x3936 565 neurons, 63811.9ms\n",
      "Speed: 653.5ms preprocess, 63811.9ms inference, 31193.4ms postprocess per image at shape (1, 3, 3456, 3936)\n",
      "Results saved to \u001b[1mruns\\segment\\predict280\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict280\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\HE_full\\TG1\\crop_7.tiff\", imgsz=[4500, 3936], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "719e2173-01bc-4111-8854-01f01f8d7af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 3936] must be multiple of max stride 32, updating to [4800, 3936]\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict280\\crop_8\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Downloads\\HE_full\\TG1\\crop_8.tiff: 3264x3936 8 neurons, 124723.7ms\n",
      "Speed: 118.6ms preprocess, 124723.7ms inference, 5.1ms postprocess per image at shape (1, 3, 3264, 3936)\n",
      "Results saved to \u001b[1mruns\\segment\\predict280\u001b[0m\n",
      "7 labels saved to runs\\segment\\predict280\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\HE_full\\TG1\\crop_8.tiff\", imgsz=[4773, 3936], max_det=800, conf=0.4, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "834236fa-b383-4c4b-98c3-37888411606c",
   "metadata": {},
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG2\\Aligned_DRG2.tif\", conf=0.4, imgsz=[4847,2195] , max_det=400, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7f7d2d7-9c59-4932-9d60-fe8b8d933c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[500] must be multiple of max stride 32, updating to [512]\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_2000\\stage21_C2f_features.png... (32/512)\n",
      "image 1/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_0_2000.tif: 512x512 (no detections), 36673.0ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_0_4500\\stage21_C2f_features.png... (32/512)\n",
      "image 2/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_0_4500.tif: 512x512 (no detections), 23349.6ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_4000\\stage21_C2f_features.png... (32/512)\n",
      "image 3/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_1000_4000.tif: 512x512 (no detections), 23039.9ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_5000\\stage21_C2f_features.png... (32/512)\n",
      "image 4/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_1000_5000.tif: 512x512 (no detections), 24486.4ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1000_6500\\stage21_C2f_features.png... (32/512)\n",
      "image 5/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_1000_6500.tif: 512x512 (no detections), 21728.4ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_2000\\stage21_C2f_features.png... (32/512)\n",
      "image 6/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_1500_2000.tif: 512x512 11 neurons, 22272.2ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_3000\\stage21_C2f_features.png... (32/512)\n",
      "image 7/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_1500_3000.tif: 512x512 12 neurons, 24507.1ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_4000\\stage21_C2f_features.png... (32/512)\n",
      "image 8/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_1500_4000.tif: 512x512 (no detections), 25437.3ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_500\\stage21_C2f_features.png... (32/512)\n",
      "image 9/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_1500_500.tif: 512x512 4 neurons, 22119.4ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_1500_6500\\stage21_C2f_features.png... (32/512)\n",
      "image 10/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_1500_6500.tif: 512x512 (no detections), 23219.5ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_3000\\stage21_C2f_features.png... (32/512)\n",
      "image 11/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_2000_3000.tif: 512x512 7 neurons, 22299.9ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2000_4500\\stage21_C2f_features.png... (32/512)\n",
      "image 12/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_2000_4500.tif: 512x512 (no detections), 22777.2ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_2500_1500\\stage21_C2f_features.png... (32/512)\n",
      "image 13/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_2500_1500.tif: 512x512 8 neurons, 26161.0ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4000_5000\\stage21_C2f_features.png... (32/512)\n",
      "image 14/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_4000_5000.tif: 512x512 (no detections), 22117.1ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_4500_500\\stage21_C2f_features.png... (32/512)\n",
      "image 15/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_4500_500.tif: 512x512 (no detections), 22288.6ms\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_1_500_1500\\stage21_C2f_features.png... (32/512)\n",
      "image 16/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_1_500_1500.tif: 512x512 15 neurons, 27436.6ms\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_2_0_3500\\stage21_C2f_features.png... (32/512)\n",
      "image 17/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_2_0_3500.tif: 512x512 11 neurons, 22115.0ms\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_2_1500_4000\\stage21_C2f_features.png... (32/512)\n",
      "image 18/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_2_1500_4000.tif: 512x512 (no detections), 21164.4ms\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_2_500_3500\\stage21_C2f_features.png... (32/512)\n",
      "image 19/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_2_500_3500.tif: 512x512 16 neurons, 22422.2ms\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_3_0_2000\\stage21_C2f_features.png... (32/512)\n",
      "image 20/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_3_0_2000.tif: 512x512 (no detections), 27450.0ms\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_3_1500_1500\\stage21_C2f_features.png... (32/512)\n",
      "image 21/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_3_1500_1500.tif: 512x512 3 neurons, 21930.8ms\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_3_2000_1000\\stage21_C2f_features.png... (32/512)\n",
      "image 22/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_3_2000_1000.tif: 512x512 (no detections), 22168.6ms\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict258\\DRG_3_3500_500\\stage21_C2f_features.png... (32/512)\n",
      "image 23/23 C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\\DRG_3_3500_500.tif: 512x512 (no detections), 20626.6ms\n",
      "Speed: 7.9ms preprocess, 23817.0ms inference, 37.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "Results saved to \u001b[1mruns\\segment\\predict258\u001b[0m\n",
      "9 labels saved to runs\\segment\\predict258\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Downloads\\Watson_Segmentation\\pipelines\\DRG123_Merged\\test\\images\", conf=0.4, imgsz=500, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cf21e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mouse\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\ultralytics\\nn\\tasks.py:781: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "trained_model=r\"runs\\segment\\train144\\weights\\last.pt\" #path to previously trained model; can use last or best .pt\n",
    "model=YOLO(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a67c64-f8c8-4c15-95bf-904ef883271c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 6500] must be multiple of max stride 32, updating to [4512, 6528]\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict265\\crop_1\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_1.tiff: 4512x3136 358 neurons, 58138.9ms\n",
      "Speed: 125.1ms preprocess, 58138.9ms inference, 4315.2ms postprocess per image at shape (1, 3, 4512, 3136)\n",
      "Results saved to \u001b[1mruns\\segment\\predict265\u001b[0m\n",
      "1 label saved to runs\\segment\\predict265\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_1.tiff\", conf=0.4, imgsz=[4500, 6500], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83e75cb-28ba-4aa4-b06f-5c602fd4b253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 6300] must be multiple of max stride 32, updating to [4800, 6304]\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_2.tiff: 4800x3648 581 neurons, 68898.3ms\n",
      "Speed: 134.3ms preprocess, 68898.3ms inference, 20171.5ms postprocess per image at shape (1, 3, 4800, 3648)\n",
      "Results saved to \u001b[1mruns\\segment\\predict266\u001b[0m\n",
      "1 label saved to runs\\segment\\predict266\\labels\n"
     ]
    }
   ],
   "source": [
    "vresult=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_2.tiff\", conf=0.4, imgsz=[4773, 6300], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75b28977-fcf8-4d9a-85d8-2978c2dc51dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 2200] must be multiple of max stride 32, updating to [4512, 2208]\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_3\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_3.tiff: 1088x2208 450 neurons, 28618.0ms\n",
      "Speed: 27.6ms preprocess, 28618.0ms inference, 2276.2ms postprocess per image at shape (1, 3, 1088, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict266\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict266\\labels\n"
     ]
    }
   ],
   "source": [
    "vresult=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_3.tiff\", conf=0.4, imgsz=[4500, 2200], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f8f739-2e26-43b8-85a4-c9a4db62cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 2000] must be multiple of max stride 32, updating to [4800, 2016]\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_4\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_4.tiff: 864x2016 255 neurons, 25227.8ms\n",
      "Speed: 19.6ms preprocess, 25227.8ms inference, 11.0ms postprocess per image at shape (1, 3, 864, 2016)\n",
      "Results saved to \u001b[1mruns\\segment\\predict266\u001b[0m\n",
      "3 labels saved to runs\\segment\\predict266\\labels\n"
     ]
    }
   ],
   "source": [
    "vresult=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_4.tiff\", conf=0.4, imgsz=[4773, 2000], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8647b5-3487-41bc-8544-b86cbc6e23af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 2180] must be multiple of max stride 32, updating to [4512, 2208]\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_5\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_5.tiff: 1088x2208 395 neurons, 27628.6ms\n",
      "Speed: 25.9ms preprocess, 27628.6ms inference, 197.3ms postprocess per image at shape (1, 3, 1088, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict266\u001b[0m\n",
      "4 labels saved to runs\\segment\\predict266\\labels\n"
     ]
    }
   ],
   "source": [
    "vresult=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_5.tiff\", conf=0.4, imgsz=[4500, 2180], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ce7048-1d5d-4758-be98-5e1110e96616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 2180] must be multiple of max stride 32, updating to [4800, 2208]\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_6\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_6.tiff: 1024x2208 38 neurons, 27309.9ms\n",
      "Speed: 24.9ms preprocess, 27309.9ms inference, 63.7ms postprocess per image at shape (1, 3, 1024, 2208)\n",
      "Results saved to \u001b[1mruns\\segment\\predict266\u001b[0m\n",
      "5 labels saved to runs\\segment\\predict266\\labels\n"
     ]
    }
   ],
   "source": [
    "vresult=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_6.tiff\", conf=0.4, imgsz=[4773, 2180], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfa3b925-4083-40c6-bbe9-48b364fe6852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 3936] must be multiple of max stride 32, updating to [4512, 3936]\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_7\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_7.tiff: 3456x3936 600 neurons, 57757.3ms\n",
      "Speed: 144.7ms preprocess, 57757.3ms inference, 3014.2ms postprocess per image at shape (1, 3, 3456, 3936)\n",
      "Results saved to \u001b[1mruns\\segment\\predict266\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict266\\labels\n"
     ]
    }
   ],
   "source": [
    "vresult=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_7.tiff\", conf=0.4, imgsz=[4500, 3936], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1497f29-751f-4e7e-852a-464b949cde87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 3936] must be multiple of max stride 32, updating to [4800, 3936]\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict266\\crop_8\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_8.tiff: 3264x3936 (no detections), 52675.7ms\n",
      "Speed: 147.5ms preprocess, 52675.7ms inference, 1.0ms postprocess per image at shape (1, 3, 3264, 3936)\n",
      "Results saved to \u001b[1mruns\\segment\\predict266\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict266\\labels\n"
     ]
    }
   ],
   "source": [
    "vresult=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\TG1crop\\ST\\crop_8.tiff\", conf=0.4, imgsz=[4773, 3936], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbd09b3f-3963-4750-b747-9aff8a9753d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[3224, 9477] must be multiple of max stride 32, updating to [3232, 9504]\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict245\\crop_15\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try5\\crop_1.tif: 3232x1120 828 neurons, 31988.8ms\n",
      "Speed: 423.8ms preprocess, 31988.8ms inference, 16449.5ms postprocess per image at shape (1, 3, 3232, 1120)\n",
      "Results saved to \u001b[1mruns\\segment\\predict245\u001b[0m\n",
      "3 labels saved to runs\\segment\\predict245\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try5\\crop_1.tif\", conf=0.4, imgsz=[3224, 9477], max_det=1500, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04d328db-9555-4d03-a65a-8a1285171cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[3224, 9477] must be multiple of max stride 32, updating to [3232, 9504]\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict245\\crop_24\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try5\\crop_2.tif: 3232x1120 491 neurons, 33656.7ms\n",
      "Speed: 43.8ms preprocess, 33656.7ms inference, 1167.8ms postprocess per image at shape (1, 3, 3232, 1120)\n",
      "Results saved to \u001b[1mruns\\segment\\predict245\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict245\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try5\\crop_2.tif\", conf=0.4, imgsz=[3224, 9477], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82b2fc3e-1dc5-4c13-92fc-2aa4c2270dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[3224, 9477] must be multiple of max stride 32, updating to [3232, 9504]\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict245\\crop_34\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try5\\crop_3.tif: 3232x1120 264 neurons, 32016.6ms\n",
      "Speed: 35.9ms preprocess, 32016.6ms inference, 22.6ms postprocess per image at shape (1, 3, 3232, 1120)\n",
      "Results saved to \u001b[1mruns\\segment\\predict245\u001b[0m\n",
      "6 labels saved to runs\\segment\\predict245\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try5\\crop_3.tif\", conf=0.4, imgsz=[3224, 9477], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdb4658d-7a81-4aac-bebc-b98c02d6b623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2468, 9477] must be multiple of max stride 32, updating to [2496, 9504]\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict246\\crop_1\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try6\\crop_1.tif: 2496x672 307 neurons, 67639.3ms\n",
      "Speed: 14.9ms preprocess, 67639.3ms inference, 447.8ms postprocess per image at shape (1, 3, 2496, 672)\n",
      "Results saved to \u001b[1mruns\\segment\\predict246\u001b[0m\n",
      "1 label saved to runs\\segment\\predict246\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try6\\crop_1.tif\", conf=0.4, imgsz=[2468, 9477], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3bc65ab-531d-464c-b726-ec8018ee0c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2468, 9477] must be multiple of max stride 32, updating to [2496, 9504]\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict246\\crop_2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try6\\crop_2.tif: 2496x672 378 neurons, 26243.2ms\n",
      "Speed: 15.0ms preprocess, 26243.2ms inference, 336.0ms postprocess per image at shape (1, 3, 2496, 672)\n",
      "Results saved to \u001b[1mruns\\segment\\predict246\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict246\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try6\\crop_2.tif\", conf=0.4, imgsz=[2468, 9477], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c55cc7b-c320-4d64-b532-b0d52e942b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2468, 9477] must be multiple of max stride 32, updating to [2496, 9504]\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict246\\crop_3\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try6\\crop_3.tif: 2496x672 152 neurons, 38760.8ms\n",
      "Speed: 13.9ms preprocess, 38760.8ms inference, 14.9ms postprocess per image at shape (1, 3, 2496, 672)\n",
      "Results saved to \u001b[1mruns\\segment\\predict246\u001b[0m\n",
      "3 labels saved to runs\\segment\\predict246\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try6\\crop_3.tif\", conf=0.4, imgsz=[2468, 9477], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ca95702-99b9-4340-8a48-c8349c222763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 3200] must be multiple of max stride 32, updating to [4512, 3200]\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict247\\crop_1\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_1.tiff: 2304x3200 643 neurons, 39831.7ms\n",
      "Speed: 53.2ms preprocess, 39831.7ms inference, 12831.2ms postprocess per image at shape (1, 3, 2304, 3200)\n",
      "Results saved to \u001b[1mruns\\segment\\predict247\u001b[0m\n",
      "1 label saved to runs\\segment\\predict247\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_1.tiff\", conf=0.4, imgsz=[4500, 3200], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55efc7c8-c1dd-41e3-a960-8ec9aa671828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 3200] must be multiple of max stride 32, updating to [4800, 3200]\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict247\\crop_2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_2.tiff: 2176x3200 706 neurons, 40838.5ms\n",
      "Speed: 61.1ms preprocess, 40838.5ms inference, 10808.9ms postprocess per image at shape (1, 3, 2176, 3200)\n",
      "Results saved to \u001b[1mruns\\segment\\predict247\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict247\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_2.tiff\", conf=0.4, imgsz=[4773, 3200], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2ca3f65-2f59-451e-abbf-9bbb4591fa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 3000] must be multiple of max stride 32, updating to [4512, 3008]\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict247\\crop_3\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_3.tiff: 2016x3008 658 neurons, 44134.2ms\n",
      "Speed: 50.9ms preprocess, 44134.2ms inference, 846.1ms postprocess per image at shape (1, 3, 2016, 3008)\n",
      "Results saved to \u001b[1mruns\\segment\\predict247\u001b[0m\n",
      "3 labels saved to runs\\segment\\predict247\\labels\n"
     ]
    }
   ],
   "source": [
    "#result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_3.tiff\", conf=0.4, imgsz=[4500, 3000], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cfd7729-fa92-4e20-967b-88b3277f9720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4773, 3677] must be multiple of max stride 32, updating to [4800, 3680]\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict247\\crop_4\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_4.tiff: 2336x3680 190 neurons, 53436.8ms\n",
      "Speed: 80.8ms preprocess, 53436.8ms inference, 465.8ms postprocess per image at shape (1, 3, 2336, 3680)\n",
      "Results saved to \u001b[1mruns\\segment\\predict247\u001b[0m\n",
      "4 labels saved to runs\\segment\\predict247\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_4.tiff\", conf=0.4, imgsz=[4773, 3677], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ced1d62-5ade-4a99-87b6-e184d85e147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[4500, 3677] must be multiple of max stride 32, updating to [4512, 3680]\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict248\\crop_5\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_5.tiff: 3008x3680 533 neurons, 51301.3ms\n",
      "Speed: 82.9ms preprocess, 51301.3ms inference, 2902.2ms postprocess per image at shape (1, 3, 3008, 3680)\n",
      "Results saved to \u001b[1mruns\\segment\\predict248\u001b[0m\n",
      "1 label saved to runs\\segment\\predict248\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\TG1_crop\\try7\\crop_5.tiff\", conf=0.4, imgsz=[4500, 3677], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7aa119d-1e77-4a1f-9aca-43761ee3e7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2124, 5797] must be multiple of max stride 32, updating to [2144, 5824]\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict249\\crop_1\\stage21_C2f_features.png... (32/512)\n",
      "image 1/2 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_1.tiff: 2144x800 162 neurons, 46907.8ms\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict249\\crop_2\\stage21_C2f_features.png... (32/512)\n",
      "image 2/2 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_2.tiff: 2144x1984 228 neurons, 57533.1ms\n",
      "Speed: 317.2ms preprocess, 52220.5ms inference, 3106.5ms postprocess per image at shape (1, 3, 2144, 1984)\n",
      "Results saved to \u001b[1mruns\\segment\\predict249\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict249\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\", conf=0.4, imgsz=[2124, 5797], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3d51632-9ad4-437e-a123-659f2f2af7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2124, 5797] must be multiple of max stride 32, updating to [2144, 5824]\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict250\\crop_1\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_1.tiff: 2144x800 162 neurons, 27911.1ms\n",
      "Speed: 16.0ms preprocess, 27911.1ms inference, 295.1ms postprocess per image at shape (1, 3, 2144, 800)\n",
      "Results saved to \u001b[1mruns\\segment\\predict250\u001b[0m\n",
      "1 label saved to runs\\segment\\predict250\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_1.tiff\", conf=0.4, imgsz=[2124, 5797], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027c7dd5-8818-4225-a21d-c79ffa38d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[5361, 5797] must be multiple of max stride 32, updating to [5376, 5824]\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage0_Conv_features.png... (32/32)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage1_Conv_features.png... (32/64)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage2_C2f_features.png... (32/64)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage3_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage4_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage5_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage6_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage7_Conv_features.png... (32/512)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage8_C2f_features.png... (32/512)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage9_SPPF_features.png... (32/512)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage10_Upsample_features.png... (32/512)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage11_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage12_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage13_Upsample_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage14_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage15_C2f_features.png... (32/128)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage16_Conv_features.png... (32/128)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage17_Concat_features.png... (32/384)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage18_C2f_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage19_Conv_features.png... (32/256)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage20_Concat_features.png... (32/768)\n",
      "Saving runs\\segment\\predict250\\crop_2\\stage21_C2f_features.png... (32/512)\n",
      "image 1/1 C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_2.tiff: 5376x4992 278 neurons, 84801.7ms\n",
      "Speed: 257.6ms preprocess, 84801.7ms inference, 8087.1ms postprocess per image at shape (1, 3, 5376, 4992)\n",
      "Results saved to \u001b[1mruns\\segment\\predict250\u001b[0m\n",
      "2 labels saved to runs\\segment\\predict250\\labels\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(r\"C:\\Users\\Mouse\\Desktop\\mergedimages\\finalimages\\DRG1cropped\\crop_2.tiff\", conf=0.4, imgsz=[5361,5797], max_det=800, show_boxes=False, save_txt=True, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46558c-e058-42cb-8c18-ff1527f2bfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
