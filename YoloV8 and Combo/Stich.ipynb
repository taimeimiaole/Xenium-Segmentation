{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1c80b4-8e9d-49e6-92d4-a068e9b2ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('C:\\\\Users\\\\Mouse\\\\Downloads\\\\YOLO_new_merged\\\\DRG1\\\\DRG1\\\\crop_1.tiff', 'C:\\\\Users\\\\Mouse\\\\Downloads\\\\YOLO_new_merged\\\\DRG1\\\\crop_1.txt', (0, 0, 2400, 5797))\n",
      "[[[ 0  0 26]\n",
      "  [ 0  0 29]\n",
      "  [ 0  0 23]\n",
      "  ...\n",
      "  [ 0  0 22]\n",
      "  [ 0  0 23]\n",
      "  [ 0  0 24]]\n",
      "\n",
      " [[ 0  0 21]\n",
      "  [ 0  0 26]\n",
      "  [ 0  0 22]\n",
      "  ...\n",
      "  [ 0  0 23]\n",
      "  [ 0  0 24]\n",
      "  [ 0  0 29]]\n",
      "\n",
      " [[ 0  0 20]\n",
      "  [ 0  0 22]\n",
      "  [ 0  0 21]\n",
      "  ...\n",
      "  [ 0  0 25]\n",
      "  [ 0  0 25]\n",
      "  [ 0  0 24]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]]\n",
      "('C:\\\\Users\\\\Mouse\\\\Downloads\\\\YOLO_new_merged\\\\DRG1\\\\DRG1\\\\crop_2.tiff', 'C:\\\\Users\\\\Mouse\\\\Downloads\\\\YOLO_new_merged\\\\DRG1\\\\crop_2.txt', (2200, 0, 7261, 5797))\n",
      "[[[ 0  0 18]\n",
      "  [ 0  0 20]\n",
      "  [ 0  0 21]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0 27]\n",
      "  [ 0  0 22]\n",
      "  [ 0  0 22]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0 20]\n",
      "  [ 0  0 21]\n",
      "  [ 0  0 26]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]\n",
      "\n",
      " [[ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  ...\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]\n",
      "  [ 0  0  0]]]\n",
      "470\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A linearring requires at least 4 coordinates.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 352\u001b[0m\n\u001b[0;32m    349\u001b[0m output_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMouse\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mYOLO_new_merged\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAligned_DRG1.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m output_annotations_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMouse\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mYOLO_new_merged\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 352\u001b[0m \u001b[43mmerge_crops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotations_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_annotations_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMouse\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mYOLO_new_merged\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcrop_1.tiff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMouse\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mYOLO_new_merged\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcrop_2.tiff\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m    \n\u001b[0;32m    356\u001b[0m ]\n\u001b[0;32m    357\u001b[0m annotations_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMouse\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mYOLO_new_merged\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcrop_1.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMouse\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mYOLO_new_merged\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDRG1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcrop_2.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m     \n\u001b[0;32m    359\u001b[0m     \u001b[38;5;66;03m#r\"C:\\Users\\Mouse\\Downloads\\final_runs\\ST\\txts\\DRG1\\DRG1_crop1.txt\", r\"C:\\Users\\Mouse\\Downloads\\final_runs\\ST\\txts\\DRG1\\DRG1_crop2.txt\"\u001b[39;00m\n\u001b[0;32m    360\u001b[0m ]\n",
      "Cell \u001b[1;32mIn[10], line 266\u001b[0m, in \u001b[0;36mmerge_crops\u001b[1;34m(images, annotations_files, coordinates, output_image_path, output_annotations_path)\u001b[0m\n\u001b[0;32m    263\u001b[0m     final_annotations\u001b[38;5;241m.\u001b[39mextend(transformed_annotations)\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(final_annotations))\n\u001b[1;32m--> 266\u001b[0m to_delete \u001b[38;5;241m=\u001b[39m \u001b[43mfind_overlapping_rois\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_annotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(to_delete))\n\u001b[0;32m    268\u001b[0m final_annotations \u001b[38;5;241m=\u001b[39m delete_cells(final_annotations, to_delete)\n",
      "Cell \u001b[1;32mIn[10], line 100\u001b[0m, in \u001b[0;36mfind_overlapping_rois\u001b[1;34m(annotations, coordinates)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Convert annotation points to Shapely polygons\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, points \u001b[38;5;129;01min\u001b[39;00m annotations:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Create a Shapely Polygon from the points\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     polygon \u001b[38;5;241m=\u001b[39m \u001b[43mPolygon\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     polygons[\u001b[38;5;28mcls\u001b[39m] \u001b[38;5;241m=\u001b[39m polygon\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Check for overlaps\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\shapely\\geometry\\polygon.py:230\u001b[0m, in \u001b[0;36mPolygon.__new__\u001b[1;34m(self, shell, holes)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shell\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     shell \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m holes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(holes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;66;03m# shapely constructor cannot handle holes=[]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\shapely\\geometry\\polygon.py:104\u001b[0m, in \u001b[0;36mLinearRing.__new__\u001b[1;34m(self, coordinates)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(coordinates) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# empty geometry\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# TODO better constructor + should shapely.linearrings handle this?\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shapely\u001b[38;5;241m.\u001b[39mfrom_wkt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLINEARRING EMPTY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m geom \u001b[38;5;241m=\u001b[39m \u001b[43mshapely\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinearrings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(geom, LinearRing):\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid values passed to LinearRing constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\shapely\\decorators.py:77\u001b[0m, in \u001b[0;36mmultithreading_enabled.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[0;32m     76\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\shapely\\creation.py:171\u001b[0m, in \u001b[0;36mlinearrings\u001b[1;34m(coords, y, z, indices, out, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m coords \u001b[38;5;241m=\u001b[39m _xyz_to_coords(coords, y, z)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinearrings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m simple_geometries_1d(coords, indices, GeometryType\u001b[38;5;241m.\u001b[39mLINEARRING, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[1;31mValueError\u001b[0m: A linearring requires at least 4 coordinates."
     ]
    }
   ],
   "source": [
    "#Stitiching together .txt output files when prediction is run on cropped images\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shapely\n",
    "import re\n",
    "\n",
    "def parse_annotations(file_path):\n",
    "    \"\"\"Parse YOLOv8 annotations from a text file, handling empty files safely.\"\"\"\n",
    "    annotations = []\n",
    "    count = 1\n",
    "    filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    if os.stat(file_path).st_size == 0:  # Check if the file is empty\n",
    "        print(f\"Warning: {file_path} is empty. No annotations parsed.\")\n",
    "        return annotations  # Return empty list\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:  # Skip empty lines\n",
    "                continue\n",
    "            cls = filename + '_roi' + str(count)\n",
    "            bbox = list(map(float, parts[1:]))  # YOLO format: class, freehand array\n",
    "            annotations.append((cls, bbox))\n",
    "            count += 1\n",
    "    return annotations\n",
    "\n",
    "\n",
    "def save_annotations(file_path, annotations, final_width, final_height):\n",
    "    \"\"\"Save YOLOv8 annotations to a text file with normalized bounding box coordinates rounded to 6 decimal places.\"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        yolo_standard = 0\n",
    "        for cls, bbox in annotations:\n",
    "            # Normalize and round bbox\n",
    "            print(bbox)\n",
    "            normalized_bbox = [\n",
    "                round(coord / final_width, 6) if i % 2 == 0 else round(coord / final_height, 6)\n",
    "                for i, coord in enumerate(bbox)\n",
    "            ]\n",
    "            # Write the normalized bbox to the file\n",
    "            file.write(f\"{yolo_standard} {' '.join(map(str, normalized_bbox))}\\n\")\n",
    "\n",
    "def transform_annotations(annotations, offset_x, offset_y, scale_x=1.0, scale_y=1.0):\n",
    "    \"\"\"\n",
    "    Transform annotations for freehand shapes by applying offsets and scaling.\n",
    "    Redundant points are removed, and all coordinates are rounded to integers.\n",
    "    \n",
    "    Args:\n",
    "        annotations (list): List of tuples where each tuple contains a class label \n",
    "                            and an array of points in the format \n",
    "                            [x1, y1, x2, y2, ..., xn, yn].\n",
    "        offset_x (float): Horizontal offset to apply.\n",
    "        offset_y (float): Vertical offset to apply.\n",
    "        scale_x (float): Horizontal scaling factor. Default is 1.0.\n",
    "        scale_y (float): Vertical scaling factor. Default is 1.0.\n",
    "    \n",
    "    Returns:\n",
    "        list: Transformed annotations with updated coordinates, without redundant points.\n",
    "    \"\"\"\n",
    "    transformed = []\n",
    "    \n",
    "    for cls, points in annotations:\n",
    "        # Apply transformation to each point in the array\n",
    "        transformed_points = []\n",
    "        unique_points = set()  # Keep track of unique (x, y) pairs\n",
    "        for i in range(0, len(points), 2):  # Process in pairs (x, y)\n",
    "            # Transform coordinates and round to nearest integer\n",
    "            x = round(points[i] * scale_x + offset_x)\n",
    "            y = round(points[i + 1] * scale_y + offset_y)\n",
    "            # Add unique points only\n",
    "            if (x, y) not in unique_points:\n",
    "                unique_points.add((x, y))\n",
    "                transformed_points.extend([x, y])  # Append transformed (x, y)\n",
    "                \n",
    "        transformed_points.extend([transformed_points[0], transformed_points[1]])\n",
    "        \n",
    "        # Append the transformed annotation\n",
    "        transformed.append((cls, transformed_points))\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def find_overlapping_rois(annotations, coordinates):\n",
    "    \"\"\"\n",
    "    Find and print the names of ROIs that overlap.\n",
    "    \n",
    "    Args:\n",
    "        annotations (list): List of tuples where each tuple contains a class label \n",
    "                            and an array of points in the format \n",
    "                            [x1, y1, x2, y2, ..., xn, yn].\n",
    "    \"\"\"\n",
    "    # Create a dictionary to hold the polygons with their class labels\n",
    "    polygons = {}\n",
    "    \n",
    "    # Convert annotation points to Shapely polygons\n",
    "    for cls, points in annotations:\n",
    "        # Create a Shapely Polygon from the points\n",
    "        polygon = Polygon([(points[i], points[i + 1]) for i in range(0, len(points), 2)])\n",
    "        polygons[cls] = polygon\n",
    "\n",
    "    # Check for overlaps\n",
    "    overlapping_rois = set()\n",
    "    roi_names = list(polygons.keys())\n",
    "    \n",
    "    for i in range(len(roi_names)):\n",
    "        for j in range(i + 1, len(roi_names)):\n",
    "            roi1 = roi_names[i]\n",
    "            roi2 = roi_names[j]\n",
    "            # Check if the polygons overlap\n",
    "            if polygons[roi1].overlaps(polygons[roi2]):\n",
    "                overlapping_rois.add((roi1, roi2))\n",
    "    def extract_number_from_crop(string):\n",
    "        match = re.search(r'crop[_]?(\\d+)', string)  # Finds \"crop1\" or \"crop_1\"\n",
    "        return int(match.group(1)) if match else None  # Extract just the number\n",
    "        \n",
    "    def compare_crop_numbers(string1, string2):\n",
    "        # Split the strings by underscore\n",
    "        parts1 = extract_number_from_crop(string1)\n",
    "        parts2 = extract_number_from_crop(string2)\n",
    "        \n",
    "        # Extract the second part (the crop number)\n",
    "        crop_number1 = int(parts1)  # \"2\" from \"crop_2_roi1\"\n",
    "        crop_number2 = int(parts2)  # \"2\" from \"crop_2_roi76\"\n",
    "        \n",
    "        # Compare the crop numbers\n",
    "        return crop_number1 == crop_number2\n",
    "\n",
    "    def get_overlap_coordinates(string1, string2, coordinates):\n",
    "        \n",
    "        # Split the strings by underscore\n",
    "        parts1 = extract_number_from_crop(string1)\n",
    "        parts2 = extract_number_from_crop(string2)\n",
    "        \n",
    "        # Extract the second part (the crop number)\n",
    "        crop_number1 = int(parts1)  # \"2\" from \"crop2_roi1\"\n",
    "        crop_number2 = int(parts2)  # \"2\" from \"crop2_roi76\"\n",
    "        \n",
    "        # Unpack the boxes\n",
    "        x1_1, y1_1, x2_1, y2_1 = coordinates[crop_number1-1]\n",
    "        x1_2, y1_2, x2_2, y2_2 = coordinates[crop_number2-1]\n",
    "        \n",
    "        # Compute the coordinates of the intersection box\n",
    "        x1_intersection = max(x1_1, x1_2)\n",
    "        y1_intersection = max(y1_1, y1_2)\n",
    "        x2_intersection = min(x2_1, x2_2)\n",
    "        y2_intersection = min(y2_1, y2_2)\n",
    "        \n",
    "        # If there is no intersection, return None\n",
    "        if x1_intersection >= x2_intersection or y1_intersection >= y2_intersection:\n",
    "            return None  # No overlap\n",
    "        \n",
    "        # Return the coordinates of the overlap\n",
    "        return (x1_intersection, y1_intersection, x2_intersection, y2_intersection)\n",
    "\n",
    "    def calculate_roi_differences(roi, x_min, y_min, x_max, y_max):\n",
    "        \"\"\"\n",
    "        Calculate the differences between the bounding box of the ROI and the provided coordinates.\n",
    "        \n",
    "        Args:\n",
    "            roi: List of coordinates representing the ROI as [x1, y1, x2, y2, x3, y3, ...]\n",
    "            x_min, y_min: The minimum x and y values (e.g., the lower-left corner of a rectangle).\n",
    "            x_max, y_max: The maximum x and y values (e.g., the upper-right corner of a rectangle).\n",
    "            \n",
    "        Returns:\n",
    "            roi_x_min_diff, roi_y_min_diff, roi_x_max_diff, roi_y_max_diff: The differences\n",
    "            between the ROI's bounding box and the provided bounding box.\n",
    "        \"\"\"\n",
    "        # Calculate the min and max x and y values of the ROI (bounding box)\n",
    "        roi_x_min = min(roi[::2])  # Min of x1, x2, x3, ...\n",
    "        roi_y_min = min(roi[1::2])  # Min of y1, y2, y3, ...\n",
    "        roi_x_max = max(roi[::2])  # Max of x1, x2, x3, ...\n",
    "        roi_y_max = max(roi[1::2])  # Max of y1, y2, y3, ...\n",
    "        \n",
    "        # Calculate the differences\n",
    "        roi_x_min_diff = roi_x_min - x_min\n",
    "        roi_y_min_diff = roi_y_min - y_min\n",
    "        roi_x_max_diff = x_max - roi_x_max\n",
    "        roi_y_max_diff = y_max - roi_y_max\n",
    "        \n",
    "        return roi_x_min_diff, roi_y_min_diff, roi_x_max_diff, roi_y_max_diff\n",
    "    \n",
    "    to_delete = set()  # Use a set to avoid duplicates\n",
    "\n",
    "    for roi_pair in overlapping_rois:\n",
    "        if not compare_crop_numbers(roi_pair[0], roi_pair[1]):\n",
    "            x_min, y_min, x_max, y_max = get_overlap_coordinates(roi_pair[0], roi_pair[1], coordinates)\n",
    "            \n",
    "            roi1_coordinates = next(points for cls, points in annotations if cls == roi_pair[0])\n",
    "            roi2_coordinates = next(points for cls, points in annotations if cls == roi_pair[1])\n",
    "    \n",
    "            roi1_metrics = calculate_roi_differences(roi1_coordinates, x_min, y_min, x_max, y_max)\n",
    "            roi2_metrics = calculate_roi_differences(roi2_coordinates, x_min, y_min, x_max, y_max)\n",
    "            \n",
    "            # Compare areas and keep track of the smaller one\n",
    "            roi1_val = min(roi1_metrics)\n",
    "            roi2_val = min(roi2_metrics)\n",
    "    \n",
    "            if roi1_val < 0:\n",
    "                to_delete.add(roi_pair[1])  # Add to set instead of list\n",
    "            elif roi2_val < 0:\n",
    "                to_delete.add(roi_pair[0])  # Add to set instead of list\n",
    "            else:\n",
    "                polygon1 = polygons[roi_pair[0]]\n",
    "                polygon2 = polygons[roi_pair[1]]\n",
    "                \n",
    "                # Calculate the areas of the polygons\n",
    "                area1 = polygon1.area\n",
    "                area2 = polygon2.area\n",
    "                if area1 < area2:\n",
    "                    smaller_pair = roi_pair[0]\n",
    "                    smaller_area = area1\n",
    "                else:\n",
    "                    smaller_pair = roi_pair[1]\n",
    "                    smaller_area = area2\n",
    "                to_delete.add(smaller_pair)  # Add to set instead of list\n",
    "    \n",
    "    # Return as a list (convert set to list)\n",
    "    return list(to_delete)\n",
    "\n",
    "def delete_cells(annotations, to_delete):\n",
    "    \"\"\"\n",
    "    Remove annotations from the list that match the ROI names in the to_delete list.\n",
    "    \n",
    "    Args:\n",
    "        annotations (list): List of tuples, where each tuple contains a class label and an array of points.\n",
    "        to_delete (list): List of ROI names to delete.\n",
    "        \n",
    "    Returns:\n",
    "        list: A new list with the annotations that are not in the to_delete list.\n",
    "    \"\"\"\n",
    "    # Filter annotations to exclude those whose ROI name is in the to_delete list\n",
    "    updated_annotations = [annotation for annotation in annotations if annotation[0] not in to_delete]\n",
    "    \n",
    "    return updated_annotations\n",
    "        \n",
    "\n",
    "def merge_crops(images, annotations_files, coordinates, output_image_path, output_annotations_path):\n",
    "    \"\"\"Merge crops into one image and compile annotations.\"\"\"\n",
    "    # Initialize variables for stitching\n",
    "    final_height = max(y2 for _, y1, _, y2 in coordinates)\n",
    "    final_width = max(x2 for x1, _, x2, _ in coordinates)\n",
    "    stitched_image = np.zeros((final_height, final_width, 3), dtype=np.uint8)\n",
    "\n",
    "    # List to hold all annotations\n",
    "    final_annotations = []\n",
    "\n",
    "    # Iterate through each crop\n",
    "    for i, (image_path, annotation_path, (x1, y1, x2, y2)) in enumerate(zip(images, annotations_files, coordinates)):\n",
    "        # Read and place the image\n",
    "        crop_image = cv2.imread(image_path)\n",
    "        print((image_path, annotation_path, (x1, y1, x2, y2)))\n",
    "        print(crop_image)\n",
    "        stitched_image[y1:y2, x1:x2] = crop_image\n",
    "\n",
    "        # Transform annotations\n",
    "        crop_annotations = parse_annotations(annotation_path)\n",
    "        transformed_annotations = transform_annotations(crop_annotations, x1, y1)\n",
    "        #transformed_annotations = transform_annotations(crop_annotations, x1, y1, x2-x1, y2-y1)\n",
    "\n",
    "        # Add transformed annotations to the final list\n",
    "        final_annotations.extend(transformed_annotations)\n",
    "        \n",
    "    print(len(final_annotations))\n",
    "    to_delete = find_overlapping_rois(final_annotations, coordinates)\n",
    "    print(len(to_delete))\n",
    "    final_annotations = delete_cells(final_annotations, to_delete)\n",
    "    print(len(final_annotations))\n",
    "    \n",
    "    draw_rois_matplotlib(final_annotations, output_image_path, final_width, final_height)\n",
    "    \n",
    "    # Save final annotations\n",
    "    save_annotations(output_annotations_path, final_annotations, final_width, final_height)\n",
    "\n",
    "    # Save final image\n",
    "    cv2.imwrite(output_image_path, stitched_image)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_rois_matplotlib(rois, image_path=None, final_width=None, final_height=None):\n",
    "    \"\"\"\n",
    "    Overlay ROIs onto an image (provided as a file path) and display using Matplotlib.\n",
    "    \n",
    "    Args:\n",
    "        rois (list): List of tuples where each tuple contains a class label \n",
    "                     and an array of points in the format \n",
    "                     [x1, y1, x2, y2, ..., xn, yn].\n",
    "        image_path (str): Path to the background image to overlay ROIs.\n",
    "                          If None, a blank image is created.\n",
    "        final_width (int): Width of the image (required if `image_path` is None).\n",
    "        final_height (int): Height of the image (required if `image_path` is None).\n",
    "    \"\"\"\n",
    "    if image_path is not None:\n",
    "        # Load the image from the provided file path\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image file not found at path: {image_path}\")\n",
    "        \n",
    "        # Get the image dimensions\n",
    "        final_height, final_width = image.shape[:2]\n",
    "    else:\n",
    "        if final_width is None or final_height is None:\n",
    "            raise ValueError(\"final_width and final_height must be provided if no image is given.\")\n",
    "        # Create a blank white image\n",
    "        image = np.ones((final_height, final_width, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Iterate through the ROIs\n",
    "    for cls, points in rois:\n",
    "        # Convert points into a format compatible with OpenCV\n",
    "        polygon = np.array(points, dtype=np.int32).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Draw the polygon on the image\n",
    "        color = (255, 255, 0)  # Red color for the ROI\n",
    "        thickness = 2\n",
    "        cv2.polylines(image, [polygon], isClosed=True, color=color, thickness=thickness)\n",
    "        \n",
    "        # Optionally, draw the label near the ROI\n",
    "        text_position = (polygon[0][0][0], polygon[0][0][1] - 10)  # Slightly above the first point\n",
    "        cv2.putText(image, cls, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Convert the image from BGR to RGB for Matplotlib\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image using Matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')  # Hide axes for better visualization\n",
    "    plt.title(\"ROIs Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input data\n",
    "    images = [r\"path to crop image 1\", r\"path to crop image 2\", \n",
    "]\n",
    "    annotations_files = [r\"path to .txt file for crop image 1\", r\"path to .txt file for crop image 2\"\n",
    "        \n",
    "        #r\"C:\\Users\\Mouse\\Downloads\\final_runs\\ST\\txts\\DRG1\\DRG1_crop1.txt\", r\"C:\\Users\\Mouse\\Downloads\\final_runs\\ST\\txts\\DRG1\\DRG1_crop2.txt\", \n",
    "]\n",
    "    coordinates = [\n",
    "        (0, 0, 2400, 5797),     # First crop coordinates (same coordinates used to crop the full image)\n",
    "        (2200, 0, 7261, 5797), # Second crop coordinates\n",
    "    ]\n",
    "\n",
    "    # Output paths\n",
    "    output_image_path = r\"path to original \"\n",
    "    output_annotations_path = r\"C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\DRG1.txt\"\n",
    "\n",
    "    merge_crops(images, annotations_files, coordinates, output_image_path, output_annotations_path)\n",
    "    \n",
    "    images = [r\"C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\DRG1\\crop_1.tiff\", r\"C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\DRG1\\crop_2.tiff\"\n",
    "       \n",
    "    ]\n",
    "    annotations_files = [r\"C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\crop_1.txt\", r\"C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\crop_2.txt\"\n",
    "        \n",
    "        #r\"C:\\Users\\Mouse\\Downloads\\final_runs\\ST\\txts\\DRG1\\DRG1_crop1.txt\", r\"C:\\Users\\Mouse\\Downloads\\final_runs\\ST\\txts\\DRG1\\DRG1_crop2.txt\"\n",
    "    ]\n",
    "    coordinates = [\n",
    "        (0, 0, 2400, 5797),     # First crop\n",
    "        (2200, 0, 7261, 5797), # Second crop\n",
    "    ]\n",
    "    output_image_path = r\"C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\DRG1\\Aligned_DRG1.tif\"\n",
    "    output_annotations_path = r\"C:\\Users\\Mouse\\Downloads\\YOLO_new_merged\\DRG1\\DRG1.txt\"\n",
    "    # Merge crops and save results\n",
    "    merge_crops(images, annotations_files, coordinates, output_image_path, output_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548fcede-2dc2-4f01-a100-42d049a01944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
